{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b58206b26c764c02a5dcc77a022b7b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6afddafd20254a0aa4895e311000f104",
              "IPY_MODEL_f1e98261f3ce46139ae4b037bd0ea918",
              "IPY_MODEL_f21284f9f56040f3abc9585bdd99816c"
            ],
            "layout": "IPY_MODEL_a0a9ec8e01254b63a7659c4476fbc5c7"
          }
        },
        "6afddafd20254a0aa4895e311000f104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c2934caa814a4a97b84f4d28a15686",
            "placeholder": "​",
            "style": "IPY_MODEL_7427c25da71547f0b03dbeba6b01378e",
            "value": "Upserted vectors: 100%"
          }
        },
        "f1e98261f3ce46139ae4b037bd0ea918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d93420720cb945e6a5094781ec5c8ba8",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b9f3faaa52444498b3f5e7d5ba058e",
            "value": 55
          }
        },
        "f21284f9f56040f3abc9585bdd99816c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de1e4e251d240e281f1921ab7913fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d401f7ed4b404fecb9239fa5b2aeb675",
            "value": " 55/55 [02:25&lt;00:00, 37.46it/s]"
          }
        },
        "a0a9ec8e01254b63a7659c4476fbc5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c2934caa814a4a97b84f4d28a15686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7427c25da71547f0b03dbeba6b01378e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93420720cb945e6a5094781ec5c8ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b9f3faaa52444498b3f5e7d5ba058e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8de1e4e251d240e281f1921ab7913fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d401f7ed4b404fecb9239fa5b2aeb675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reachrkr/llamaindexrag/blob/main/LlamaIndex_Tutorials_VectorStore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q openai\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate\n",
        "!pip install -q optimum[exporters]\n",
        "!pip install -q InstructorEmbedding\n",
        "!pip install -q sentence_transformers\n",
        "!pip install -q pypdf\n",
        "!pip install -q chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q llama-index chromadb --quiet\n",
        "!pip install -q chromadb\n",
        "!pip install -q sentence-transformers\n",
        "!pip install -q pydantic==1.10.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxGOAxDUvKlE",
        "outputId": "0a3e60f4-603e-49a5-dce7-852b73770392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/3.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/3.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/3.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/3.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-OPENAI-API-KEY\""
      ],
      "metadata": {
        "id": "3LYEnctgbBWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl https://www.ipcc.ch/report/ar6/wg2/downloads/report/IPCC_AR6_WGII_Chapter03.pdf --output IPCC_AR6_WGII_Chapter03.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y_E6BUZrYp-",
        "outputId": "3961379e-00c5-4505-d079-8e6ce2c76ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 20.7M  100 20.7M    0     0  79.7M      0 --:--:-- --:--:-- --:--:-- 79.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.vector_stores import ChromaVectorStore\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.embeddings import HuggingFaceEmbedding\n",
        "from llama_index.llms import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "import chromadb\n"
      ],
      "metadata": {
        "id": "482wzQ6mvYxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define embedding function\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
      ],
      "metadata": {
        "id": "8pfCTvG9vY8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"Orca_paper.pdf\"]\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "MPhHSUtnvY_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YB_KolqI3pg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHROMA-DB"
      ],
      "metadata": {
        "id": "-8jlgXGp47cu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bP1CgwWR4H5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create client and a new collection\n",
        "chroma_client = chromadb.EphemeralClient()\n",
        "chroma_collection = chroma_client.create_collection(\"orca_paper\")"
      ],
      "metadata": {
        "id": "FLmWj6-dwVyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hG5Hlw2V4Q_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up ChromaVectorStore and load in data\n"
      ],
      "metadata": {
        "id": "_4zBzlbcwLq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up ChromaVectorStore and load in data\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n"
      ],
      "metadata": {
        "id": "g1KwBHHuwKyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ],
      "metadata": {
        "id": "TPDtjS5P4fn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)"
      ],
      "metadata": {
        "id": "XnwdnuZn4frc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context)"
      ],
      "metadata": {
        "id": "Psv-DFtX4ful"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What are some of the main contributions of this new Orca model?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "M9KHTQG8wK3_",
        "outputId": "ed5ba2d9-fde5-4772-97fa-a29f0987201a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The main contributions of the Orca model include its ability to retain the constraints and limitations of the LLaMA model family, its potential for efficient and scalable tool-augmented LFM systems, and its alignment with the GPT-4 model in terms of safety measures and content moderation. Additionally, the Orca model demonstrates relative safety in generating neutral content compared to other models like ChatGPT and GPT-4. It also showcases the potential for tool-augmented LFMs to address limitations and interact with the environment for up-to-date knowledge retrieval."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Persist: Saving to Disk"
      ],
      "metadata": {
        "id": "WFasbpZJ0TUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "\n",
        "chroma_collection = db.get_or_create_collection(\"DB_collection\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model,\n",
        "                                               chunk_size=800,\n",
        "                                               chunk_overlap=20)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context, service_context=service_context\n",
        ")"
      ],
      "metadata": {
        "id": "B5i5lxQrvZCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V69BQgST6aId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load from Disk"
      ],
      "metadata": {
        "id": "Hs9Z8BmH1BaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load from disk\n",
        "db2 = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "chroma_collection = db2.get_or_create_collection(\"DB_collection\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store,\n",
        "    service_context=service_context,\n",
        ")"
      ],
      "metadata": {
        "id": "Ytlj_EPVvZFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What are some of the main contributions of this new Orca model?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "nJ1bh3zh1OD7",
        "outputId": "52d8adfa-0b78-4f6b-b3b8-c97f3ee2aad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Some nature-based solutions that can help us fight climate change include marine protected areas (MPAs), habitat restoration, habitat development, and maintaining sustainable fisheries. These solutions can protect ecosystem services, support biodiversity, and mitigate climate change. They can also enhance the resilience of marine ecosystems and provide societal and ecological benefits regardless of the level of climate change. Additionally, carefully designed and placed MPAs can increase resilience to climate change by removing additional stressors on ecosystems. Restoration of coastal habitats such as mangroves, salt marshes, and seagrass meadows can effectively remove carbon dioxide from the atmosphere and protect coasts from the impacts of storms and sea level rise. Sustainable fishing is also considered a nature-based solution as it contributes to food production and supports the UN's Sustainable Development Goal of Zero Hunger."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h-qGk3n-7Suh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PINECONE"
      ],
      "metadata": {
        "id": "QBWGp_dP6mPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pinecone-client"
      ],
      "metadata": {
        "id": "XOr6p10m1OJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone"
      ],
      "metadata": {
        "id": "i_nzoUZh1OM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PINECONE_API_KEY'] = \"PINECONE_API_KEY\"\n",
        "os.environ['PINECONE_ENVIRONMENT'] = 'gcp-starter'\n"
      ],
      "metadata": {
        "id": "vEzw43BoC5P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize connection to pinecone\n",
        "pinecone.init(\n",
        "    api_key=os.environ['PINECONE_API_KEY'],\n",
        "    environment=os.environ['PINECONE_ENVIRONMENT']\n",
        ")"
      ],
      "metadata": {
        "id": "ZTokcpnr1OP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the index if it does not exist already\n",
        "index_name = 'llamaindex'\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        index_name,\n",
        "        dimension=768,\n",
        "        metric='cosine'\n",
        "    )"
      ],
      "metadata": {
        "id": "wwAPbSv8Dy6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_index = pinecone.Index(\"llamaindex\")\n",
        "pinecone.describe_index(\"llamaindex\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmA9O7nqENlK",
        "outputId": "e8735c6e-2c52-44e1-c786-6b6eeecdf171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IndexDescription(name='llamaindex', metric='cosine', replicas=1, dimension=768.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.vector_stores import PineconeVectorStore"
      ],
      "metadata": {
        "id": "kltmj58fENod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set add_sparse_vector=True to compute sparse vectors during upsert\n",
        "from llama_index.storage.storage_context import StorageContext"
      ],
      "metadata": {
        "id": "FL9KY3P8ENrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = PineconeVectorStore(\n",
        "    pinecone_index=pinecone_index,\n",
        "    # add_sparse_vector=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "IwT2d7oFENu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n"
      ],
      "metadata": {
        "id": "xTzwIpi5ENy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        storage_context=storage_context,\n",
        "                                        service_context=service_context\n",
        "                                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b58206b26c764c02a5dcc77a022b7b38",
            "6afddafd20254a0aa4895e311000f104",
            "f1e98261f3ce46139ae4b037bd0ea918",
            "f21284f9f56040f3abc9585bdd99816c",
            "a0a9ec8e01254b63a7659c4476fbc5c7",
            "e3c2934caa814a4a97b84f4d28a15686",
            "7427c25da71547f0b03dbeba6b01378e",
            "d93420720cb945e6a5094781ec5c8ba8",
            "60b9f3faaa52444498b3f5e7d5ba058e",
            "8de1e4e251d240e281f1921ab7913fc9",
            "d401f7ed4b404fecb9239fa5b2aeb675"
          ]
        },
        "id": "WKW4s4YoEN1V",
        "outputId": "06674e1e-a7c9-41f5-fc28-822277a02dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upserted vectors:   0%|          | 0/55 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b58206b26c764c02a5dcc77a022b7b38"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Data\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response = query_engine.query(\"What is Big-Bench Hard test?\")\n",
        "\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "id": "yQ2waFYsFOfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "c589b140-6b7a-4b15-c0f1-1c28e428d0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Big-Bench Hard is a suite of 23 challenging tasks that were introduced to measure the capabilities and limitations of large language models. These tasks are specifically designed to be difficult and have been selected based on the fact that prior language models did not outperform the average human-rater on them. The evaluation of Big-Bench Hard tasks is done using standard zero-shot prompting, without the use of any labeled examples."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W0Y1fjC4FOjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_17Kx7aFOmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNXSbsstFOpb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}