{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reachrkr/llamaindexrag/blob/main/YT_RetrievalQA_withLLaMA2_70b_Together_API_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "RRYSu48huSUW"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain huggingface_hub tiktoken\n",
        "!pip -q install chromadb\n",
        "!pip -q install PyPDF2 pypdf InstructorEmbedding sentence_transformers\n",
        "!pip -q install --upgrade together"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RetrievalQA with LLaMA 2-70B on Together API"
      ],
      "metadata": {
        "id": "gvIjaK53dP5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"04092ddcc33f35f78e0a0623e0dac43d8987d4eb65726d79ad936c1079435243\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "J-KFB7J_u_3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36409ba8-58ea-4b69-8724-058ce6d124f4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.334\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, anyio, async-timeout, dataclasses-json, jsonpatch, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Together API\n"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "\n",
        "# set your API key\n",
        "together.api_key = os.environ[\"TOGETHER_API_KEY\"]\n",
        "\n",
        "# list available models and descriptons\n",
        "models = together.Models.list()"
      ],
      "metadata": {
        "id": "B3pqftc7nacA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "id": "fUsVuNAGYAqx",
        "outputId": "fc48bdb3-7012-4403-d927-cb37a69be53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e831864b84b428b8d322d0',\n",
              "  'name': 'Austism/chronos-hermes-13b',\n",
              "  'display_name': 'Chronos Hermes (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'This model is a 75/25 merge of Chronos (13B) and Nous Hermes (13B) models resulting in having a great ability to produce evocative storywriting and follow a narrative.',\n",
              "  'license': 'other',\n",
              "  'creator_organization': 'Austism',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['</s>'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:08:25.379Z',\n",
              "  'update_at': '2023-08-24T17:08:25.379Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xFA5C96b20a10cAC5d21E095e6F4f8c3CBC2f3527': 1,\n",
              "    '0xa96806eD1168d759DC233DfB636522b72bBbE159': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.614187938Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.029997705,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 17.210764,\n",
              "   'throughput_out': 3.2297263}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6532f0faf94bacfc629b4cf7',\n",
              "  'name': 'EleutherAI/llemma_7b',\n",
              "  'display_name': 'Llemma (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Llemma 7B is a language model for mathematics. It was initialized with Code Llama 7B weights, and trained on the Proof-Pile-2 for 200B tokens.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/EleutherAI/llemma_7b',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6738546688,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-10-20T21:28:26.403Z',\n",
              "  'update_at': '2023-10-24T17:42:38.630Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xcFF8989b33958D1640798CD1A7BDc96AF9420C55': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.151914712Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023918305,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11959152,\n",
              "   'throughput_out': 6.7245364}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc1',\n",
              "  'name': 'EleutherAI/pythia-12b-v0',\n",
              "  'display_name': 'Pythia (12B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/EleutherAI/pythia-12b-v0',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 12000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.091Z',\n",
              "  'update_at': '2023-06-23T20:22:42.091Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x6376511C715189a6E25495fb3744a5E419F9e520': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.14919897Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecbe',\n",
              "  'name': 'EleutherAI/pythia-1b-v0',\n",
              "  'display_name': 'Pythia (1B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/EleutherAI/pythia-1b-v0',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 1000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.925Z',\n",
              "  'update_at': '2023-06-23T20:22:41.925Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xAB4d9Fb5cC9d29edf6f9c19F47c9E54c7D33431d': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:17.592098013Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecbf',\n",
              "  'name': 'EleutherAI/pythia-2.8b-v0',\n",
              "  'display_name': 'Pythia (2.8B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
              "  'license': 'apache-2.0',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'num_parameters': 2800000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.975Z',\n",
              "  'update_at': '2023-06-23T20:22:41.975Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x2903afA0159904c4fE9cABF528495bd9eE91A6b1': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.457945942Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc0',\n",
              "  'name': 'EleutherAI/pythia-6.9b',\n",
              "  'display_name': 'Pythia (6.9B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'The Pythia Scaling Suite is a collection of models developed to facilitate interpretability research.',\n",
              "  'license': 'apache-2.0',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'num_parameters': 6900000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.044Z',\n",
              "  'update_at': '2023-06-23T20:22:42.044Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xBE2A33177Ca1a8AD6b2e04c713372eA2ec412B8E': 1},\n",
              "   'asks_updated': '2023-11-12T02:33:57.240091622Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f78861d683768020b9f005',\n",
              "  'name': 'Gryphe/MythoMax-L2-13b',\n",
              "  'display_name': 'MythoMax-L2 (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'MythoLogic-L2 and Huginn merge using a highly experimental tensor type merge technique. The main difference with MythoMix is that I allowed more of Huginn to intermingle with the single tensors located at the front and end of a model',\n",
              "  'license': 'other',\n",
              "  'creator_organization': 'Gryphe',\n",
              "  'hardware_label': '1x A40 48GB',\n",
              "  'num_parameters': 13000000000,\n",
              "  'release_date': '2023-08-01T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T19:58:25.683Z',\n",
              "  'update_at': '2023-09-05T19:58:25.683Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 919,\n",
              "   'num_bids': 903,\n",
              "   'num_running': 903,\n",
              "   'asks': {'0x09610eE37B51Fc29eaBb8AeA43a57F7E23Bdefc8': 30,\n",
              "    '0x09a7E14cE1E3a5B5d77e27DD0002Ddc13c979691': 28,\n",
              "    '0x15d950e7a86dd574E93217F7b9dB8Fb36Cf18F46': 4,\n",
              "    '0x1665e19f3A7e5182f63FfD541a69d6b3aDEC806A': 2,\n",
              "    '0x17D8F3e78333B5CB63AcbD33828c7B8215fF392D': 14,\n",
              "    '0x18a8F30763A9b0ab488f21e753Eb7e3503EC9012': 1,\n",
              "    '0x1D0FB3cEd4C102d7DD3F5A7f91Ee107894567fe3': 1,\n",
              "    '0x230c2bA3d3a3f526426E7cCE08cddC0fAC8dDB54': 36,\n",
              "    '0x2c31381F43719123B79849Dc4dA85dC6CDF1A274': 1,\n",
              "    '0x319EA81d9626121c35921443090248B18e8Aa94b': 78,\n",
              "    '0x35E577980db3239CEf88954D02eBdef1502a3663': 1,\n",
              "    '0x3BE3510cAD17fe36620B4296F13EBB830366E486': 11,\n",
              "    '0x41EbeCeB5FA3BD1aA6F98C9F14Ffd51cA053C332': 1,\n",
              "    '0x46CF94Edae8A3EEa4E26b01908f53Dab6c0B7917': 1,\n",
              "    '0x508d805F7a9dc8Ccb1E515ce00dB8F4f6F3c00Cc': 1,\n",
              "    '0x53db12AE9b135179fF38551eb97354374BC3f8c1': 2,\n",
              "    '0x54572A971a153aE1D9C9A15A9BDcb997516Ee62D': 18,\n",
              "    '0x553360413A22980874F6e8617949eF2C5dEBbfa3': 4,\n",
              "    '0x55CF563C1cC006baB50eC7a7a39B4E9ab04a3a28': 1,\n",
              "    '0x596B525a329196029345E8e0f8661f8576604C62': 4,\n",
              "    '0x5A54A7df4936BceE33DCA74730e2542f6AdFBC14': 26,\n",
              "    '0x5C6466982F46A42365A33e44B1D010Ffad3d9f3F': 46,\n",
              "    '0x6E27b5f1E9E39d3277457Cc3F627285c54376463': 63,\n",
              "    '0x6aDB0E30543eBF4bcEB08f761d5c7De8Eb657558': 70,\n",
              "    '0x725392F86fbD4DCe5BeEbdE2e053dA6836F59a05': 30,\n",
              "    '0x756f18675f603Cf4623dd05e970853fB1Aa013c4': 2,\n",
              "    '0x8758F5E16BE5869B824273A025D40Ac9197fe0eB': 2,\n",
              "    '0x8B7329d450Ff460fe8684d13DAbcE9f547bd8a27': 40,\n",
              "    '0x8eE3e2FB034B2917ae94c3831CF7Eb8Cdf54d9b4': 115,\n",
              "    '0x9448778cE36de31eeF37b64a88bD23e5b86B6EaD': 3,\n",
              "    '0x9ED364372a59cd7374AF4A4E8e10985ee39022cA': 8,\n",
              "    '0x9dc451E6A2B390E2d85971964F69647dF6f664dE': 32,\n",
              "    '0xA41c377401dbf3e0866a6bd80AEB94ac40Ac2549': 2,\n",
              "    '0xB4E600E39345B32aa8962e1Ea49611021f8692C5': 3,\n",
              "    '0xB884A78c0D4bEC2cBEB7f11FFb2a27dbe46E1e9e': 112,\n",
              "    '0xBc70B9CA1A9D59e9dF18c5Fa0b85Fa7C6Ea332Be': 1,\n",
              "    '0xD3fEB2B8eF1929e07EE21E3c6c4f79Dc8e7068d7': 1,\n",
              "    '0xD58096501178C2F486f6b886FEA7c67e12e1eADD': 2,\n",
              "    '0xD597Dc32F631DF9023122Ab3E03FdBd441730DAa': 1,\n",
              "    '0xD6C9C5982f080D97dE5561Bd9E01Ae6DDc16E70A': 9,\n",
              "    '0xDfE55E7CD61D6E54bFd9591dbbBf9F285566eEC7': 2,\n",
              "    '0xEeD6519B911a66642D863070919143FA20e8E0eE': 39,\n",
              "    '0xF3460D53B54E103724F2e16A9279aB52748757E9': 2,\n",
              "    '0xFa993B9F9cA9D617Fbc054BB889bdf9D110B02dE': 2,\n",
              "    '0xab94D3b3A847ED9f1d8D006e887A0cd2eB0965Cf': 33,\n",
              "    '0xb1B6eccE4D7Ed09B1d9BBB1Db6A5922Cc0F24969': 1,\n",
              "    '0xcc3659829eeed35b833687aD2e048C2A088A8457': 10,\n",
              "    '0xd4dfeFEbE63784d8BBb24A41eF73A8c527A26739': 2,\n",
              "    '0xf246e65ab06d03FB172eBbB5B23A6970765C26F1': 21},\n",
              "   'asks_updated': '2023-11-12T17:06:13.828834044Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 18.758871,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 40064.016,\n",
              "   'throughput_out': 9543.609}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acefbe227f790586239d40',\n",
              "  'name': 'HuggingFaceH4/starchat-alpha',\n",
              "  'display_name': 'StarCoderChat Alpha (16B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Fine-tuned from StarCoder to act as a helpful coding assistant. As an alpha release is only intended for educational or research purpopses.',\n",
              "  'license': 'bigcode-openrail-m',\n",
              "  'link': 'https://huggingface.co/HuggingFaceH4/starchat-alpha',\n",
              "  'creator_organization': 'HuggingFaceH4',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 16000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|endoftext|>', '<|end|>'],\n",
              "   'prompt_format': '<|system|>\\n<|end|>\\n<|user|>\\n{prompt}<|end|>\\n<|assistant|>'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:59:26.298Z',\n",
              "  'update_at': '2023-07-11T05:59:26.298Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x001fd7d3dCf2085A17fE9B6499180Eca87abB7cE': 1},\n",
              "   'asks_updated': '2023-11-12T09:34:11.799963649Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 1.73767e-25,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 1.3344122e-22,\n",
              "   'throughput_out': 7.8615297e-23}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acebb2227f790586239d16',\n",
              "  'name': 'NousResearch/Nous-Hermes-13b',\n",
              "  'display_name': 'Nous Hermes (13B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'LLaMA 13B fine-tuned on over 300,000 instructions. Designed for long responses, low hallucination rate, and absence of censorship mechanisms.',\n",
              "  'license': 'gpl, LLaMA License Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-13b',\n",
              "  'creator_organization': 'Nous Research',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:42:10.444Z',\n",
              "  'update_at': '2023-07-11T05:42:10.444Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x7cA1082c90A01Cd7E42637751E76c7a6325D5aFD': 1},\n",
              "   'asks_updated': '2023-11-12T08:48:12.863847488Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.00012660818,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.9728469,\n",
              "   'throughput_out': 0.26140106}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64cae18d3ede2fa7e2cbcc7d',\n",
              "  'name': 'NousResearch/Nous-Hermes-Llama2-13b',\n",
              "  'display_name': 'Nous Hermes Llama-2 (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Nous-Hermes-Llama2-13b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
              "  'license': 'mit',\n",
              "  'creator_organization': 'Nous Research',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
              "   'stop': ['###', '</s>']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-08-02T23:06:53.926Z',\n",
              "  'update_at': '2023-10-07T00:19:33.779Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 19,\n",
              "   'num_bids': 9,\n",
              "   'num_running': 9,\n",
              "   'asks': {'0x0D53DB030355dDa9Bc7973EB57b09bBdf238AB80': 1,\n",
              "    '0x147383B31719BcFFF22E084608675179D3ea13A4': 2,\n",
              "    '0x1cC1AEe80049A16831a0c55b17B2A4663a891741': 2,\n",
              "    '0x27848b3C50Ad9Fba1A2b18A9b5CD3EEa2f14BC4C': 2,\n",
              "    '0x41C25A406b37F5DB19aFdCf44235500b8BDEeB15': 2,\n",
              "    '0x885A3E8DC52Aa45D5FB886063bcE1d22dBEA77Ce': 2,\n",
              "    '0x91eAC4b38D0A4c2C98851350eaEb25f99eCcB62a': 1,\n",
              "    '0xD3CD3fc3Bb6c882dbA4c01BB10014E2a81C9c334': 3,\n",
              "    '0xe0173b0447B5b32c64cd50979e366B0cc8Ab6FbD': 3,\n",
              "    '0xf85F810579a740D35778c03e6aD0CCD44ce413bE': 1},\n",
              "   'asks_updated': '2023-11-12T06:32:58.483611791Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 11.950398,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 60480.07,\n",
              "   'throughput_out': 2467.9807}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6532f0faf94bacfc629b4cf8',\n",
              "  'name': 'NousResearch/Nous-Hermes-Llama2-70b',\n",
              "  'display_name': 'Nous Hermes LLaMA-2 (70B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Nous-Hermes-Llama2-70b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-Llama2-70b',\n",
              "  'creator_organization': 'NousResearch',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 70000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['###', '</s>'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n'},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-10-20T21:28:26.404Z',\n",
              "  'update_at': '2023-10-24T17:43:39.278Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0x9c12E6313B59799fe3c9da9d6D6a2bBc88bC6580': 2},\n",
              "   'asks_updated': '2023-11-12T15:22:36.058857155Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.015023585,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 52.16172,\n",
              "   'throughput_out': 2.7011065}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6532f0faf94bacfc629b4cf6',\n",
              "  'name': 'NousResearch/Nous-Hermes-llama-2-7b',\n",
              "  'display_name': 'Nous Hermes LLaMA-2 (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Nous-Hermes-Llama2-7b is a state-of-the-art language model fine-tuned on over 300,000 instructions.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/NousResearch/Nous-Hermes-llama-2-7b',\n",
              "  'creator_organization': 'NousResearch',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6738415616,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
              "   'stop': ['###', '</s>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-10-20T21:28:26.403Z',\n",
              "  'update_at': '2023-10-24T17:41:52.365Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0xA4845663a0c61e906cB0A2A53DcFE488dF651d33': 2,\n",
              "    '0xCdaaBCEF813fC6c6AB7D9eB4CF17164Bd2F2A946': 1},\n",
              "   'asks_updated': '2023-11-12T15:27:13.295360548Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023274893,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637446,\n",
              "   'throughput_out': 1.6904132}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f677bdbc372ce719b97f05',\n",
              "  'name': 'NumbersStation/nsql-llama-2-7B',\n",
              "  'display_name': 'NSQL LLaMA-2 (7B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'NSQL is a family of autoregressive open-source large foundation models (FMs) designed specifically for SQL generation tasks.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'Numbers Station',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T00:35:09.649Z',\n",
              "  'update_at': '2023-09-05T00:35:09.649Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xBb702A9526c057836fe845DF91dEAa3B5a48cc84': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.930669487Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023274893,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637446,\n",
              "   'throughput_out': 0.1740747}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6532f0faf94bacfc629b4cf5',\n",
              "  'name': 'Open-Orca/Mistral-7B-OpenOrca',\n",
              "  'display_name': 'OpenOrca Mistral (7B) 8K',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'An OpenOrca dataset fine-tune on top of Mistral 7B by the OpenOrca team.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca',\n",
              "  'creator_organization': 'OpenOrca',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7241748480,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|im_end|>'],\n",
              "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-10-20T21:28:26.403Z',\n",
              "  'update_at': '2023-10-24T00:01:52.541Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 20,\n",
              "   'num_bids': 18,\n",
              "   'num_running': 18,\n",
              "   'asks': {'0x0eEBE9784c8E2B2E60A3c991d8A8BD3B598AF3Df': 1,\n",
              "    '0x4b475a62fB11ACAa831B2d0E5db25127482babb5': 1,\n",
              "    '0x5Eb147155F503Ad169130E1B3E5e116691BC3080': 1,\n",
              "    '0x60Dfd85523e374d4761A5D35E2F135e80eFD469d': 1,\n",
              "    '0x9f9df1488caf31F27E6287cbE69f639E637B4A07': 1,\n",
              "    '0xF259457C65B856f0880a9965B515a54d7e9D717B': 1,\n",
              "    '0xcEB4bbe90791833237689148B5eA0d641E165aDc': 2,\n",
              "    '0xcfeC9A83690c2c2e12FA1214B51Cf14545ef7B16': 1,\n",
              "    '0xd2b1D3ffbd3E2813e1Cc2b52CE3A423418017C53': 1,\n",
              "    '0xd588AA325cd347981a86b3705A5522Dd5D9821C2': 1,\n",
              "    '0xe6a7E80Ea4D0C6190ada009e23f9cc53b36B030a': 3,\n",
              "    '0xe8e01588Ea3287F51C8d00baCcAB74c93bf74e57': 2,\n",
              "    '0xeBAD0Df756C231557D7579Dd5956281e2836155A': 4},\n",
              "   'asks_updated': '2023-11-12T15:25:14.354697078Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.87439513,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 5605.8647,\n",
              "   'throughput_out': 733.2067}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc8',\n",
              "  'name': 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5',\n",
              "  'display_name': 'Open-Assistant Pythia SFT-4 (12B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5',\n",
              "  'creator_organization': 'LAION',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 12000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>'],\n",
              "   'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.383Z',\n",
              "  'update_at': '2023-06-23T20:22:42.383Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x05335b53C553da8cCeE9A334d7E662877D8110A5': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.925277053Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc9',\n",
              "  'name': 'OpenAssistant/stablelm-7b-sft-v7-epoch-3',\n",
              "  'display_name': 'Open-Assistant StableLM SFT-7 (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ',\n",
              "  'license': 'cc-by-sa-4.0',\n",
              "  'link': 'https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3',\n",
              "  'creator_organization': 'LAION',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['<|endoftext|>'],\n",
              "   'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.425Z',\n",
              "  'update_at': '2023-06-23T20:22:42.425Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x6e8C6C3A7d42B20b637c8262356984BE92CeE11B': 1},\n",
              "   'asks_updated': '2023-11-11T05:22:19.770836128Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64fbbc5adfdb1e4b06b5d5cc',\n",
              "  'name': 'Phind/Phind-CodeLlama-34B-Python-v1',\n",
              "  'display_name': 'Phind Code LLaMA Python v1 (34B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'This model is fine-tuned from CodeLlama-34B-Python and achieves 69.5% pass@1 on HumanEval.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'Phind',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 33743970304,\n",
              "  'show_in_playground': 'true',\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 16384,\n",
              "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
              "   'stop': ['</s>', '###']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-09-09T00:29:14.496Z',\n",
              "  'update_at': '2023-09-09T00:29:14.496Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xa471426bFc2d34b820EE7C7a62dc9486bafcCF68': 1},\n",
              "   'asks_updated': '2023-11-12T15:27:04.750650967Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64fbbc5adfdb1e4b06b5d5cb',\n",
              "  'name': 'Phind/Phind-CodeLlama-34B-v2',\n",
              "  'display_name': 'Phind Code LLaMA v2 (34B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Phind-CodeLlama-34B-v1 trained on additional 1.5B tokens high-quality programming-related data proficient in Python, C/C++, TypeScript, Java, and more.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'Phind',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 33743970304,\n",
              "  'show_in_playground': 'true',\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 16384,\n",
              "  'config': {'prompt_format': '### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\n{prompt}n\\n### Assistant\\n',\n",
              "   'stop': ['</s>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-09-09T00:29:14.496Z',\n",
              "  'update_at': '2023-09-09T00:29:14.496Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x92C124672726325e798A1D55E1Fef1D060657f1b': 1},\n",
              "   'asks_updated': '2023-11-12T15:25:08.863423922Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 5.1535426e-07,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.008093111,\n",
              "   'throughput_out': 4.4307955e-10}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acee11227f790586239d36',\n",
              "  'name': 'SG161222/Realistic_Vision_V3.0_VAE',\n",
              "  'display_name': 'Realistic Vision 3.0',\n",
              "  'display_type': 'image',\n",
              "  'description': 'Fine-tune version of Stable Diffusion focused on photorealism.',\n",
              "  'license': 'creativeml-openrail-m',\n",
              "  'link': 'https://huggingface.co/SG161222/Realistic_Vision_V1.4',\n",
              "  'creator_organization': 'SG161222',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'config': {'height': 1024,\n",
              "   'width': 1024,\n",
              "   'steps': 20,\n",
              "   'number_of_images': 2,\n",
              "   'seed': 42},\n",
              "  'created_at': '2023-07-11T05:52:17.219Z',\n",
              "  'update_at': '2023-07-11T05:52:17.219Z',\n",
              "  'descriptionLink': '',\n",
              "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x1E128f472069E38aEF6B8f25147B42EF81f0F3C0': 1},\n",
              "   'asks_updated': '2023-11-11T03:13:48.389520721Z',\n",
              "   'gpus': {'NVIDIA A40': 1},\n",
              "   'options': {'input=text,image': 1},\n",
              "   'qps': 1.6944847e-13,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.4435826e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64fbbc5adfdb1e4b06b5d5cd',\n",
              "  'name': 'WizardLM/WizardCoder-15B-V1.0',\n",
              "  'display_name': 'WizardCoder v1.0 (15B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'This model empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'WizardLM',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 15517462528,\n",
              "  'show_in_playground': 'true',\n",
              "  'context_length': 8192,\n",
              "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n\\n### Response:\\n',\n",
              "   'stop': ['###', '<|endoftext|>']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-09-09T00:29:14.496Z',\n",
              "  'update_at': '2023-09-09T00:29:14.496Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x63199A7778a823BbfffebA3432C7c87831595648': 1},\n",
              "   'asks_updated': '2023-11-12T15:22:32.419332527Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f67555bc372ce719b97f03',\n",
              "  'name': 'WizardLM/WizardLM-70B-V1.0',\n",
              "  'display_name': 'WizardLM v1.0 (70B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'This model achieves a substantial and comprehensive improvement on coding, mathematical reasoning and open-domain conversation capacities.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'WizardLM',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 70000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} ASSISTANT:'},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T00:24:53.327Z',\n",
              "  'update_at': '2023-09-05T00:24:53.327Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0x9bFb1a1D28Bd50dE78bcb8A79663dA916ade6f3e': 2},\n",
              "   'asks_updated': '2023-11-12T15:24:59.153036146Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.06278534,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 173.57426,\n",
              "   'throughput_out': 7.0780015}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acef6e227f790586239d3f',\n",
              "  'name': 'bigcode/starcoder',\n",
              "  'display_name': 'StarCoder (16B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Trained on 80+ coding languages, uses Multi Query Attention, an 8K context window, and was trained using the Fill-in-the-Middle objective on 1T tokens.',\n",
              "  'license': 'bigcode-openrail-m',\n",
              "  'link': 'https://huggingface.co/bigcode/starcoder',\n",
              "  'creator_organization': 'BigCode',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 16000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|endoftext|>', '<|end|>']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:58:06.486Z',\n",
              "  'update_at': '2023-07-11T05:58:06.486Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x76Da1c3472516B97b42f8ABa41cCaaB57248fD1E': 1},\n",
              "   'asks_updated': '2023-11-12T15:27:09.613005066Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecb6',\n",
              "  'name': 'databricks/dolly-v2-3b',\n",
              "  'display_name': 'Dolly v2 (3B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'An instruction-following LLM based on pythia-3b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
              "  'license': 'mit',\n",
              "  'link': 'https://huggingface.co/databricks/dolly-v2-3b',\n",
              "  'creator_organization': 'Databricks',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 3000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['### End'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.524Z',\n",
              "  'update_at': '2023-06-23T20:22:41.524Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x319B7073E931Ed635dA52EE79444D0B29ccC314D': 1,\n",
              "    '0xB9363317321b4D6489F4F6EA5649Fb561A49a88B': 1},\n",
              "   'asks_updated': '2023-11-12T08:39:16.113365392Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecb7',\n",
              "  'name': 'databricks/dolly-v2-7b',\n",
              "  'display_name': 'Dolly v2 (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'An instruction-following LLM based on pythia-7b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
              "  'license': 'mit',\n",
              "  'link': 'https://huggingface.co/databricks/dolly-v2-7b',\n",
              "  'creator_organization': 'Databricks',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['### End'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.565Z',\n",
              "  'update_at': '2023-06-23T20:22:41.565Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xAc5A2142D60E5a359b6097c4fb21D26896f23d1D': 1,\n",
              "    '0xc707a80317970C32e3fB5Dbe19acc0EF725A7889': 1},\n",
              "   'asks_updated': '2023-11-12T06:23:22.668189256Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f67987bc372ce719b97f07',\n",
              "  'name': 'defog/sqlcoder',\n",
              "  'display_name': 'Sqlcoder (15B)',\n",
              "  'display_type': 'language',\n",
              "  'description': \"Defog's SQLCoder is a state-of-the-art LLM for converting natural language questions to SQL queries, fine-tuned from Bigcode's Starcoder 15B model.\",\n",
              "  'license': 'other',\n",
              "  'creator_organization': 'Defog',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 15000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|endoftext|>'],\n",
              "   'prompt_format': '### Instructions:\\n\\n{prompt}\\n\\n### Response:\\n'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T00:42:47.496Z',\n",
              "  'update_at': '2023-09-05T00:42:47.496Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0Becb58958245257D38481a6E793DA05f12309e1': 1},\n",
              "   'asks_updated': '2023-11-12T15:22:32.058323Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f676f7bc372ce719b97f04',\n",
              "  'name': 'garage-bAInd/Platypus2-70B-instruct',\n",
              "  'display_name': 'Platypus2 Instruct (70B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'An instruction fine-tuned LLaMA-2 (70B) model by merging Platypus2 (70B) by garage-bAInd and LLaMA-2 Instruct v2 (70B) by upstage.',\n",
              "  'license': 'CC BY-NC-4.0',\n",
              "  'creator_organization': 'garage-bAInd',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'num_parameters': 70000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>', '###'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T00:31:51.264Z',\n",
              "  'update_at': '2023-09-07T01:46:29.338Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x763611653e222b6a0a8b7E060FB819A1FfcDF025': 1},\n",
              "   'asks_updated': '2023-11-10T19:43:48.07821258Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02511608,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.1272348,\n",
              "   'throughput_out': 1.3153298}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acea0b227f790586239d0b',\n",
              "  'name': 'huggyllama/llama-13b',\n",
              "  'display_name': 'LLaMA (13B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:35:07.955Z',\n",
              "  'update_at': '2023-07-11T05:35:07.955Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x430582E15b703a2569d9066CeC4518ff98ad428d': 1,\n",
              "    '0x48F1D63f119474646fFCf2cF7B49258b0B8F8Ba9': 1,\n",
              "    '0xC8a1AB4a2091895a853613B5DafdE287b5f88018': 1},\n",
              "   'asks_updated': '2023-11-12T15:22:45.488967197Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acea35227f790586239d0c',\n",
              "  'name': 'huggyllama/llama-30b',\n",
              "  'display_name': 'LLaMA (30B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 33000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:35:49.870Z',\n",
              "  'update_at': '2023-07-11T05:35:49.870Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xE441cE0033288Ef1BF62dED8369C3027603c708E': 1},\n",
              "   'asks_updated': '2023-11-12T14:50:59.615072599Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acea57227f790586239d0d',\n",
              "  'name': 'huggyllama/llama-65b',\n",
              "  'display_name': 'LLaMA (65B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 65000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:36:23.656Z',\n",
              "  'update_at': '2023-07-11T05:36:23.656Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0xb4DF6A506d240a769fA8c4579B8E893C953DCA8C': 3},\n",
              "   'asks_updated': '2023-11-12T17:03:43.675324869Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.021842888,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.10921443,\n",
              "   'throughput_out': 1.1535441}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acea6e227f790586239d0e',\n",
              "  'name': 'huggyllama/llama-7b',\n",
              "  'display_name': 'LLaMA (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'An auto-regressive language model, based on the transformer architecture. The model comes in different sizes: 7B, 13B, 33B and 65B parameters.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/decapoda-research/llama-30b-hf-int4/commit/95d097b272bd0a84a164aa8116e8c09661487581#d2h-740129',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:36:46.255Z',\n",
              "  'update_at': '2023-07-11T05:36:46.255Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x3C4F8A629f0656DE757939a434e80532CDa7ecc7': 1},\n",
              "   'asks_updated': '2023-11-12T15:27:03.402493308Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acf031227f790586239d44',\n",
              "  'name': 'lmsys/fastchat-t5-3b-v1.0',\n",
              "  'display_name': 'Vicuna-FastChat-T5 (3B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chatbot trained by fine-tuning Flan-t5-xl on user-shared conversations collected from ShareGPT.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/lmsys/fastchat-t5-3b-v1.0',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'num_parameters': 3000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 512,\n",
              "  'config': {'stop': ['###', '</s>'],\n",
              "   'prompt_format': '### Human: {prompt}\\n### Assistant:'},\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T06:01:21.713Z',\n",
              "  'update_at': '2023-07-11T06:01:21.713Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x898081aaf58c59B3105569A68054475969856a84': 1},\n",
              "   'asks_updated': '2023-11-10T20:10:17.738814602Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64fbbc5adfdb1e4b06b5d5ce',\n",
              "  'name': 'lmsys/vicuna-13b-v1.5-16k',\n",
              "  'display_name': 'Vicuna v1.5 16K (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13015864320,\n",
              "  'show_in_playground': 'true',\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 16384,\n",
              "  'config': {'prompt_format': 'USER: {prompt}\\nASSISTANT:', 'stop': ['</s>']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-09-09T00:29:14.496Z',\n",
              "  'update_at': '2023-09-09T00:29:14.496Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x90E1A82183917BFd52f880DC542ab0C328D9702D': 1},\n",
              "   'asks_updated': '2023-11-12T15:25:04.21842584Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.000524855,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.098147884}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f678e7bc372ce719b97f06',\n",
              "  'name': 'lmsys/vicuna-13b-v1.5',\n",
              "  'display_name': 'Vicuna v1.5 (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
              "  'license': 'llama2',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-09-05T00:40:07.763Z',\n",
              "  'update_at': '2023-09-05T00:40:07.763Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0x4355788cD083a3DFEd4Ab134b49aeC1B9a4820ae': 1,\n",
              "    '0xF4D5c7A9a8e29fc48E1B9Cd75e47f548DbC17fAb': 2},\n",
              "   'asks_updated': '2023-11-11T23:22:30.960014202Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.08889637,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 136.91287,\n",
              "   'throughput_out': 23.045368}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '652da26579174a6bc507647f',\n",
              "  'name': 'lmsys/vicuna-7b-v1.5',\n",
              "  'display_name': 'Vicuna v1.5 (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Vicuna is a chat assistant trained by fine-tuning Llama 2 on user-shared conversations collected from ShareGPT.',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/lmsys/vicuna-7b-v1.5',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6738415616,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>', 'USER:'],\n",
              "   'prompt_format': 'USER: {prompt}\\nASSISTANT: Hello!'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-10-16T20:51:49.194Z',\n",
              "  'update_at': '2023-10-16T20:51:49.194Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xb73DBA565275A7403Cc93D0b99Ef5D795D0eeC05': 1},\n",
              "   'asks_updated': '2023-11-10T19:41:49.858188755Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6514c873829715ded9cd17b1',\n",
              "  'name': 'mistralai/Mistral-7B-Instruct-v0.1',\n",
              "  'display_name': 'Mistral (7B) Instruct',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'instruct fine-tuned version of Mistral-7B-v0.1',\n",
              "  'license': 'Apache-2',\n",
              "  'creator_organization': 'mistralai',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'num_parameters': 7241732096,\n",
              "  'release_date': '2023-09-27T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['[/INST]', '</s>'],\n",
              "   'prompt_format': '<s>[INST] {prompt} [/INST]'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-09-28T00:27:31.815Z',\n",
              "  'update_at': '2023-10-12T01:13:51.840Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 5,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0xEdedD1266306489E86a81c88C302c17319499427': 1,\n",
              "    '0xfAF59BA6f196EA39C1f2a5b0F4a57d84db634A61': 4},\n",
              "   'asks_updated': '2023-11-10T19:48:13.807429647Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.1530965,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 259.32462,\n",
              "   'throughput_out': 69.27193}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6514c6ee829715ded9cd17b0',\n",
              "  'name': 'mistralai/Mistral-7B-v0.1',\n",
              "  'display_name': 'Mistral (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': '7.3B parameter model that outperforms Llama 2 13B on all benchmarks, approaches CodeLlama 7B performance on code, Uses Grouped-query attention (GQA) for faster inference and Sliding Window Attention (SWA) to handle longer sequences at smaller cost',\n",
              "  'license': 'Apache-2',\n",
              "  'creator_organization': 'mistralai',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'num_parameters': 7241732096,\n",
              "  'release_date': '2023-09-27T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': '{prompt}'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-09-28T00:21:02.330Z',\n",
              "  'update_at': '2023-09-28T00:21:02.330Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x87180d1179ef1edA685F8FAd68c517050EE11FDb': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.397229882Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023274893,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637446,\n",
              "   'throughput_out': 1.0284054}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aced5c227f790586239d2b',\n",
              "  'name': 'prompthero/openjourney',\n",
              "  'display_name': 'Openjourney v4',\n",
              "  'display_type': 'image',\n",
              "  'description': 'An open source Stable Diffusion model fine tuned model on Midjourney images. ',\n",
              "  'license': 'creativeml-openrail-m',\n",
              "  'link': 'https://huggingface.co/prompthero/openjourney',\n",
              "  'creator_organization': 'Prompt Hero',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'config': {'height': 512,\n",
              "   'width': 512,\n",
              "   'steps': 20,\n",
              "   'number_of_images': 2,\n",
              "   'seed': 42},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:49:16.586Z',\n",
              "  'update_at': '2023-07-11T05:49:16.586Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x5C5b60Ea2C7046FDdf7F7be3853d046301334a85': 1,\n",
              "    '0xB2bFeaa446Cc0376249ed2d7a8f5C32E0705e556': 1},\n",
              "   'asks_updated': '2023-11-12T09:46:00.102349971Z',\n",
              "   'gpus': {'NVIDIA A40': 2},\n",
              "   'options': {'input=text,image': 2},\n",
              "   'qps': 4.887401e-28,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.2482046e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece1',\n",
              "  'name': 'runwayml/stable-diffusion-v1-5',\n",
              "  'display_name': 'Stable Diffusion 1.5',\n",
              "  'display_type': 'image',\n",
              "  'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.',\n",
              "  'license': 'creativeml-openrail-m',\n",
              "  'link': 'https://huggingface.co/runwayml/stable-diffusion-v1-5',\n",
              "  'creator_organization': 'Runway ML',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'config': {'height': 512,\n",
              "   'width': 512,\n",
              "   'steps': 20,\n",
              "   'number_of_images': 2,\n",
              "   'seed': 42},\n",
              "  'created_at': '2023-06-23T20:22:43.572Z',\n",
              "  'update_at': '2023-06-23T20:22:43.572Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x98D41CFC96e488D9810431B65Aa98EBfc87b73c8': 1},\n",
              "   'asks_updated': '2023-11-12T07:58:59.981273456Z',\n",
              "   'gpus': {'NVIDIA A40': 1},\n",
              "   'options': {'input=text,image': 1},\n",
              "   'qps': 5.312136e-28,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.4435826e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acef00227f790586239d3b',\n",
              "  'name': 'stabilityai/stable-diffusion-2-1',\n",
              "  'display_name': 'Stable Diffusion 2.1',\n",
              "  'display_type': 'image',\n",
              "  'description': 'Latent text-to-image diffusion model capable of generating photo-realistic images given any text input.',\n",
              "  'license': 'openrail++',\n",
              "  'link': 'https://huggingface.co/stabilityai/stable-diffusion-2-1',\n",
              "  'creator_organization': 'Stability AI',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'created_at': '2023-06-23T20:22:43.572Z',\n",
              "  'update_at': '2023-06-23T20:22:43.572Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': '',\n",
              "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0D96A4F403d187B804E780018e2549D36f55c65b': 1,\n",
              "    '0xc66d66f543678B11C1c7528F7F8f0C07Ed5807bE': 1},\n",
              "   'asks_updated': '2023-11-12T16:48:33.057509612Z',\n",
              "   'gpus': {'NVIDIA A100 80GB PCIe': 2},\n",
              "   'options': {'input=text,image': 2},\n",
              "   'qps': 5.756227e-14,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.65594e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64c9890c689aa3b286cfcff9',\n",
              "  'name': 'stabilityai/stable-diffusion-xl-base-1.0',\n",
              "  'display_name': 'Stable Diffusion XL 1.0',\n",
              "  'display_type': 'image',\n",
              "  'description': 'A text-to-image generative AI model that excels at creating 1024x1024 images.',\n",
              "  'license': 'openrail++',\n",
              "  'link': 'https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0',\n",
              "  'creator_organization': 'Stability AI',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'config': {'height': 1024,\n",
              "   'width': 1024,\n",
              "   'steps': 20,\n",
              "   'number_of_images': 2,\n",
              "   'seed': 42},\n",
              "  'created_at': '2023-08-01T22:37:00.851Z',\n",
              "  'update_at': '2023-08-01T22:37:00.851Z',\n",
              "  'descriptionLink': '',\n",
              "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x356059B3A5861a3f0777a55d5A7a800A36aD758A': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.151157184Z',\n",
              "   'gpus': {'NVIDIA A100 80GB PCIe': 1},\n",
              "   'options': {'input=text,image': 1},\n",
              "   'qps': 9.9764795e-05,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.8867517e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '653c053fd9679a84df55c4e7',\n",
              "  'name': 'teknium/OpenHermes-2-Mistral-7B',\n",
              "  'display_name': 'OpenHermes-2-Mistral (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'State of the art Mistral Fine-tuned on extensive public datasets',\n",
              "  'license': 'Apache-2',\n",
              "  'creator_organization': 'teknium',\n",
              "  'hardware_label': 'A40',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'num_parameters': 7241732096,\n",
              "  'release_date': '2023-10-27T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'config': {'stop': ['<|im_end|>', '<|im_start|>'],\n",
              "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n',\n",
              "   'pre_prompt': '<|im_start|>system\\nYou are thoughtful, helpful, polite, honest, and friendly<|im_end|>\\n'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-10-27T18:45:19.307Z',\n",
              "  'update_at': '2023-10-27T23:53:05.438Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 23,\n",
              "   'num_bids': 21,\n",
              "   'num_running': 21,\n",
              "   'asks': {'0x19Fa684bC7DA04E76269246a9a4E0Ce4A6e72CD9': 3,\n",
              "    '0x1eeB336590Eae228749228120afB9480c451Ebd9': 1,\n",
              "    '0x236a9D355dFa2E4E4883145fC57439B6d48d74B3': 1,\n",
              "    '0x311189AD05A35bbE911cA30916f58277c58211A1': 1,\n",
              "    '0x32AFc666157Ea258C2f278a79f5cc6F26CfdDB30': 1,\n",
              "    '0x4C2cFC4aCAA2Bb6e624FAD26f53c3bde1CAd26f7': 1,\n",
              "    '0x4d8e2C04300f85c7ec4457F709A94Efa3E42C7f9': 1,\n",
              "    '0x6Fe2966bB3102935E33769dAF271BbcFf77916d3': 1,\n",
              "    '0x6d6a04146e3bd43C5aD1F93D811ba219A5E47d6f': 2,\n",
              "    '0x8C8899B68EC32560CADbD497cB21Ac8943ECA430': 1,\n",
              "    '0x96919A844487E7F1239a6cBA314C6A11b3ec883c': 1,\n",
              "    '0xB25EA3026B22ACeBF21851aF97ED171a38Bb8d38': 6,\n",
              "    '0xC0198E84052585C7B0AD1484eaa691618bf59e15': 1,\n",
              "    '0xf9cF7F01D7463fa555f450914f1a416cE53490e3': 2},\n",
              "   'asks_updated': '2023-11-12T16:35:43.442664466Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 1.61001,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 8189.5195,\n",
              "   'throughput_out': 953.62604}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78eba589782acafe17820',\n",
              "  'name': 'togethercomputer/CodeLlama-13b-Instruct',\n",
              "  'display_name': 'Code Llama Instruct (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '13016028160',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['</s>', '[INST]']},\n",
              "  'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:09:14.381Z',\n",
              "  'update_at': '2023-08-24T17:09:14.381Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0xC011E7048e89302d22b1ec0919f1Fa9B9C977654': 1,\n",
              "    '0xe3721b6679E46589E8Bdf6f28A493af0e3BfD357': 1},\n",
              "   'asks_updated': '2023-11-11T00:25:15.113059699Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.04748661,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 20.804579,\n",
              "   'throughput_out': 3.7314286}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78eba589782acafe1781f',\n",
              "  'name': 'togethercomputer/CodeLlama-13b-Python',\n",
              "  'display_name': 'Code Llama Python (13B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '13016028160',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:09:14.381Z',\n",
              "  'update_at': '2023-08-24T17:09:14.381Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xa114fB4e436A743dddC6951d9d00096247C6B9C7': 1,\n",
              "    '0xcE061Eb892Bd2aa34340656F7593d223c31CD831': 1},\n",
              "   'asks_updated': '2023-11-11T00:25:23.648768634Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.048579756,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.47056502,\n",
              "   'throughput_out': 10.683928}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78eba589782acafe1781e',\n",
              "  'name': 'togethercomputer/CodeLlama-13b',\n",
              "  'display_name': 'Code Llama (13B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '13016028160',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:09:14.381Z',\n",
              "  'update_at': '2023-08-24T17:09:14.381Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xC50a6440D30F170491d69c89960CB2aC6c015aD8': 1},\n",
              "   'asks_updated': '2023-11-11T15:57:43.095777028Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.046549786,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.651697,\n",
              "   'throughput_out': 1.4392179}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e7934a589782acafe17823',\n",
              "  'name': 'togethercomputer/CodeLlama-34b-Instruct',\n",
              "  'display_name': 'Code Llama Instruct (34B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': 34000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['</s>', '[INST]']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:28:42.172Z',\n",
              "  'update_at': '2023-08-24T17:28:42.172Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 6,\n",
              "   'num_bids': 3,\n",
              "   'num_running': 3,\n",
              "   'asks': {'0x4a21753191b67D04a48DE1CDAc26093a5e4eB2c1': 1,\n",
              "    '0x55a91F5265BAf46101787Ff1874214Ee3CAf7d5F': 1,\n",
              "    '0xA0f607C79129A7349d991076b44f3196f7Fe50ae': 1,\n",
              "    '0xCEBDf6770F5aD91ccE669442C9e1d7A5aFBb4e25': 1,\n",
              "    '0xFD013F20eFFD4E2e526030fb971C32a95ac5e9d2': 2},\n",
              "   'asks_updated': '2023-11-12T00:43:53.248456032Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.09440338,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 562.19507,\n",
              "   'throughput_out': 45.877514}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e7934a589782acafe17822',\n",
              "  'name': 'togethercomputer/CodeLlama-34b-Python',\n",
              "  'display_name': 'Code Llama Python (34B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': 34000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:28:42.172Z',\n",
              "  'update_at': '2023-08-24T17:28:42.172Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xDa69bb657f960938610a7b0a530B3741690F8365': 1},\n",
              "   'asks_updated': '2023-11-11T00:26:34.573747688Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.04858727,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.47053698,\n",
              "   'throughput_out': 9.401216}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e7934a589782acafe17821',\n",
              "  'name': 'togethercomputer/CodeLlama-34b',\n",
              "  'display_name': 'Code Llama (34B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': 34000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:28:42.172Z',\n",
              "  'update_at': '2023-08-24T17:28:42.172Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x7bC44410bCe3265343524f72A1d77a7Ff9c36298': 1},\n",
              "   'asks_updated': '2023-11-11T00:26:32.336705344Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.046559565,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.6517459,\n",
              "   'throughput_out': 2.0090363}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78e89589782acafe1781d',\n",
              "  'name': 'togethercomputer/CodeLlama-7b-Instruct',\n",
              "  'display_name': 'Code Llama Instruct (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '6738546688',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['</s>', '[INST]']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:08:25.379Z',\n",
              "  'update_at': '2023-08-24T17:08:25.379Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xd8f9b5CcbbAA2239B137c89911763Cb9916C898c': 1},\n",
              "   'asks_updated': '2023-11-12T08:41:58.652619488Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.061300676,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 3.7683616,\n",
              "   'throughput_out': 48.184025}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78e89589782acafe1781c',\n",
              "  'name': 'togethercomputer/CodeLlama-7b-Python',\n",
              "  'display_name': 'Code Llama Python (7B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '6738546688',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:08:25.379Z',\n",
              "  'update_at': '2023-08-24T17:08:25.379Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x5C87403914f0eAD10e7F71BA28e51786830d5584': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.185143756Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.04792906,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.4615328,\n",
              "   'throughput_out': 6.4175696}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64e78e89589782acafe1781b',\n",
              "  'name': 'togethercomputer/CodeLlama-7b',\n",
              "  'display_name': 'Code Llama (7B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'Code Llama is a family of large language models for code based on Llama 2 providing infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks.',\n",
              "  'license': 'LLAMA 2 Community license Agreement (Meta)',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'num_parameters': '6738546688',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['</s>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-08-24T17:08:25.379Z',\n",
              "  'update_at': '2023-08-24T17:08:25.379Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xc19467399bC50c720f2Fe0CCcF19769726c52540': 1},\n",
              "   'asks_updated': '2023-11-12T08:38:48.88513464Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.047067437,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.6547068,\n",
              "   'throughput_out': 3.4841335}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece2',\n",
              "  'name': 'togethercomputer/GPT-JT-6B-v1',\n",
              "  'display_name': 'GPT-JT (6B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Fork of GPT-J instruction tuned to excel at few-shot prompts (blog post).',\n",
              "  'descriptionLink': 'https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/GPT-JT-6B-v1',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6700000000,\n",
              "  'release_date': '2022-11-29T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.617Z',\n",
              "  'update_at': '2023-06-23T20:22:43.617Z',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x347ed480e16d8df64575Af1b19A9bb84fA787149': 1,\n",
              "    '0x825c2eEAf8e191c9c65D333F6e97C91b3459F06C': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.148907241Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.024840014,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12420007,\n",
              "   'throughput_out': 2.3081667}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece3',\n",
              "  'name': 'togethercomputer/GPT-JT-Moderation-6B',\n",
              "  'display_name': 'GPT-JT-Moderation (6B)',\n",
              "  'display_type': 'language',\n",
              "  'description': \"This model can be used to moderate other chatbot models. Built using GPT-JT model fine-tuned on Ontocord.ai's OIG-moderation dataset v0.1.\",\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/GPT-JT-Moderation-6B',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6700000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.657Z',\n",
              "  'update_at': '2023-06-23T20:22:43.657Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0F5D8C792869B8ca4Fb838505BFecFe04201aAFE': 1,\n",
              "    '0xF5BBD2E45370550092Eb6654f2d36D67029462dE': 1},\n",
              "   'asks_updated': '2023-11-12T09:17:14.729980649Z',\n",
              "   'gpus': {'NVIDIA A100 80GB PCIe': 2},\n",
              "   'qps': 0.010115227,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.05057613,\n",
              "   'throughput_out': 2.6198437}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece4',\n",
              "  'name': 'togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
              "  'display_name': 'GPT-NeoXT-Chat-Base (20B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model fine-tuned from EleutherAIs GPT-NeoX with over 40 million instructions on carbon reduced compute.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 20000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
              "   'stop': ['<human>']},\n",
              "  'max_tokens': 995,\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.702Z',\n",
              "  'update_at': '2023-06-23T20:22:43.702Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0648b3363589FE937639A018781Ea6A1367AeDA3': 1,\n",
              "    '0xF336AF86FBFf5dc323F0964f2DF9C8fE9ce804DB': 1},\n",
              "   'asks_updated': '2023-11-12T02:35:00.452005859Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.025297573,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12648787,\n",
              "   'throughput_out': 2.316506}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace9b1227f790586239d07',\n",
              "  'name': 'togethercomputer/Koala-13B',\n",
              "  'display_name': 'Koala (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.',\n",
              "  'license': 'other',\n",
              "  'link': 'https://huggingface.co/TheBloke/koala-13B-HF',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:33:37.737Z',\n",
              "  'update_at': '2023-07-11T05:33:37.737Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x8bF5041B749E3277be8685A9B884cC54Afe7D460': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.479212906Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64c28e8742fa06a9511509d1',\n",
              "  'name': 'togethercomputer/LLaMA-2-7B-32K',\n",
              "  'display_name': 'LLaMA-2-32K (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations.\",\n",
              "  'license': 'Meta license',\n",
              "  'link': 'https://huggingface.co/togethercomputer/LLaMA-2-7B-32K',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6738415616',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 32768,\n",
              "  'config': {'stop': ['\\n\\n\\n\\n', '<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-27T15:34:31.581Z',\n",
              "  'update_at': '2023-08-17T17:07:36.346Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0x12675E9664CFC91601b2411c8885f5B3dB95d2f6': 3},\n",
              "   'asks_updated': '2023-11-12T15:27:12.135224553Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02327669,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12169181,\n",
              "   'throughput_out': 1.1721692}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64de96090d052d10425df3c9',\n",
              "  'name': 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
              "  'display_name': 'LLaMA-2-7B-32K-Instruct (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': \"Extending LLaMA-2 to 32K context, built with Meta's Position Interpolation and Together AI's data recipe and system optimizations, instruction tuned by Together\",\n",
              "  'license': 'Meta license',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 32768,\n",
              "  'config': {'prompt_format': '[INST]\\n {prompt} \\n[/INST]\\n\\n',\n",
              "   'stop': ['[INST]', '\\n\\n']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0x9Dacb4DAafc6EDA891fb305E1E0dC5a80F6d4223': 1,\n",
              "    '0xD5dabEF95D028a551BF7a24369A8a0bF80A76ae5': 2},\n",
              "   'asks_updated': '2023-11-12T16:59:45.366202418Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023337897,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11668949,\n",
              "   'throughput_out': 1.8855159}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aecee',\n",
              "  'name': 'togethercomputer/Pythia-Chat-Base-7B-v0.16',\n",
              "  'display_name': 'Pythia-Chat-Base (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model based on EleutherAIs Pythia-7B model, and is fine-tuned with data focusing on dialog-style interactions.',\n",
              "  'license': 'apache-2.0',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
              "   'stop': ['<human>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.251Z',\n",
              "  'update_at': '2023-06-23T20:22:44.251Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x42899d444e0669B867ECa64983143469F097D9c5': 1,\n",
              "    '0xb2858939d66bA1A852903fc4e9C52f6D9cD5F9C2': 1},\n",
              "   'asks_updated': '2023-11-10T19:29:04.459883648Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02383283,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11916415,\n",
              "   'throughput_out': 5.69024}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64efd5511b76196fc5a54872',\n",
              "  'name': 'togethercomputer/Qwen-7B-Chat',\n",
              "  'display_name': 'Qwen-Chat (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B-Chat is a large-model-based AI assistant, which is trained with alignment techniques.\\xa0 \\xa0',\n",
              "  'license': 'Tongyi Qianwen LICENSE AGREEMENT',\n",
              "  'creator_organization': 'Qwen',\n",
              "  'hardware_label': '1x A100 80GB',\n",
              "  'num_parameters': 7000000000,\n",
              "  'release_date': '2023-08-01T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|im_end|>', '<|im_start|>'],\n",
              "   'prompt_format': '\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-08-30T23:48:33.852Z',\n",
              "  'update_at': '2023-09-07T01:49:42.840Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0x3A30F87675923F5dE4d7468Ef492015CC6a862c7': 2},\n",
              "   'asks_updated': '2023-11-12T15:27:01.936872044Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.024581369,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12372415,\n",
              "   'throughput_out': 10.8782}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64efcc2a1b76196fc5a54870',\n",
              "  'name': 'togethercomputer/Qwen-7B',\n",
              "  'display_name': 'Qwen (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': '7B-parameter version of the large language model series, Qwen (abbr. Tongyi Qianwen), proposed by Aibaba Cloud. Qwen-7B is a Transformer-based large language model, which is pretrained on a large volume of data, including web texts, books, codes, etc.\\xa0',\n",
              "  'license': 'Tongyi Qianwen LICENSE AGREEMENT',\n",
              "  'creator_organization': 'Qwen',\n",
              "  'hardware_label': '1x A100 80GB',\n",
              "  'num_parameters': 7000000000,\n",
              "  'release_date': '2023-08-01T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 8192,\n",
              "  'config': {'stop': ['<|im_end|>', '<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-08-30T23:09:30.570Z',\n",
              "  'update_at': '2023-09-07T01:49:24.716Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0x3b8A3B15fBa1c9528653acBA88C329baE2a5a43D': 3},\n",
              "   'asks_updated': '2023-11-12T15:27:13.883475952Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023516588,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11758295,\n",
              "   'throughput_out': 2.271879}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aeceb',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-7B-Base',\n",
              "  'display_name': 'RedPajama-INCITE (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).',\n",
              "  'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6857302016',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.033Z',\n",
              "  'update_at': '2023-06-23T20:22:44.033Z',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x7c7007A3ffF953bA357CF3eeF853DD8613B07209': 1,\n",
              "    '0xa5c71572Cfa868Ef8616Bb33FccB05B49dA88d8B': 1},\n",
              "   'asks_updated': '2023-11-10T20:28:41.914827351Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02327505,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637525,\n",
              "   'throughput_out': 0.58699596}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aeced',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-7B-Chat',\n",
              "  'display_name': 'RedPajama-INCITE Chat (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-7B-v1 base model.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6857302016',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
              "   'stop': ['<human>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.190Z',\n",
              "  'update_at': '2023-06-23T20:22:44.190Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xcC9323401A6f39efd3C5fc8bFAc74D7b512abd69': 1,\n",
              "    '0xd21D8158D6065D9D38d68DEAcd5946F228499b16': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.248561639Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023274895,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637448,\n",
              "   'throughput_out': 2.5794675}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aecec',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
              "  'display_name': 'RedPajama-INCITE Instruct (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-7B-v1 base model.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6857302016',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.083Z',\n",
              "  'update_at': '2023-06-23T20:22:44.083Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x30D9d6EaFcA72F8913A8661450722E512bD06a9F': 1,\n",
              "    '0xF68F3AfE6f0e6a29A16CB73cFB3BEb86E88Df043': 1},\n",
              "   'asks_updated': '2023-11-12T04:12:30.846942391Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023338549,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.116692744,\n",
              "   'throughput_out': 1.8420719}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece5',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
              "  'display_name': 'RedPajama-INCITE (3B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Base model that aims to replicate the LLaMA recipe as closely as possible (blog post).',\n",
              "  'descriptionLink': 'https://www.together.xyz/blog/redpajama-models-v1',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '2775864320',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.751Z',\n",
              "  'update_at': '2023-06-23T20:22:43.751Z',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0aBe21E3ca185164261ef34A239C247300ac8443': 1,\n",
              "    '0x930312eb45cEDC07Ca1cFFf399e46693e1f6b0B9': 1},\n",
              "   'asks_updated': '2023-11-10T23:02:39.311571531Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023275321,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637661,\n",
              "   'throughput_out': 1.0421065}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece7',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
              "  'display_name': 'RedPajama-INCITE Chat (3B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model fine-tuned using data from Dolly 2.0 and Open Assistant over the RedPajama-INCITE-Base-3B-v1 base model.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '2775864320',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': '<human>: {prompt}\\n<bot>:',\n",
              "   'stop': ['<human>']},\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.839Z',\n",
              "  'update_at': '2023-06-23T20:22:43.839Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x314e601Ca3c385ade582C39Ea568fc5F93024899': 1,\n",
              "    '0xE5CdaceFC11371aF54F4CEa9B825E299605fC0DB': 1},\n",
              "   'asks_updated': '2023-11-11T07:44:47.726438766Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02327548,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.1163774,\n",
              "   'throughput_out': 0.6679053}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1312907e072b8aece6',\n",
              "  'name': 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
              "  'display_name': 'RedPajama-INCITE Instruct (3B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Designed for few-shot prompts, fine-tuned over the RedPajama-INCITE-Base-3B-v1 base model.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
              "  'creator_organization': 'Together',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '2775864320',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:43.796Z',\n",
              "  'update_at': '2023-06-23T20:22:43.796Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x9212cc97439F70f4a4611c5D93F37087d5DF111b': 1,\n",
              "    '0xc627592f6023D78F544e7D643e5aF32c055EEA9D': 1},\n",
              "   'asks_updated': '2023-11-12T05:21:05.948262322Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023275321,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637661,\n",
              "   'throughput_out': 0.58932877}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace317227f790586239ce2',\n",
              "  'name': 'togethercomputer/alpaca-7b',\n",
              "  'display_name': 'Alpaca (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. ',\n",
              "  'license': 'cc-by-nc-4.0',\n",
              "  'link': 'https://huggingface.co/tatsu-lab/alpaca-7b-wdiff',\n",
              "  'creator_organization': 'Stanford',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['</s>', '###'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:05:27.713Z',\n",
              "  'update_at': '2023-07-11T05:05:27.713Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x4174A3c81710BCd6C43b1F8e8f8a91B1137Baf55': 1},\n",
              "   'asks_updated': '2023-11-10T20:26:24.105536086Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023274893,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11637446,\n",
              "   'throughput_out': 1.2795011}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aecf1',\n",
              "  'name': 'togethercomputer/codegen2-16B',\n",
              "  'display_name': 'CodeGen2 (16B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'An autoregressive language models for program synthesis.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/Salesforce/codegen2-3_7B',\n",
              "  'creator_organization': 'Salesforce',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 16000000000,\n",
              "  'release_date': '2022-03-25T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['\\n\\n']},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.453Z',\n",
              "  'update_at': '2023-06-23T20:22:44.453Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x3709bdf200d58193B462Ddf8A7D36C8a188BC781': 1},\n",
              "   'asks_updated': '2023-11-12T07:37:19.905531848Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace476227f790586239cef',\n",
              "  'name': 'togethercomputer/codegen2-7B',\n",
              "  'display_name': 'CodeGen2 (7B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'An autoregressive language models for program synthesis.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/Salesforce/codegen2-3_7B',\n",
              "  'creator_organization': 'Salesforce',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'release_date': '2022-03-25T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['\\n\\n']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:11:18.328Z',\n",
              "  'update_at': '2023-07-11T05:11:18.328Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xd28161c2c7Cab0b6fb262914434ee097bebF1E2E': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.140862776Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace614227f790586239cf7',\n",
              "  'name': 'togethercomputer/falcon-40b-instruct',\n",
              "  'display_name': 'Falcon Instruct (40B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Falcon-40B-Instruct is a causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize. ',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/tiiuae/falcon-40b-instruct',\n",
              "  'creator_organization': 'TII UAE',\n",
              "  'hardware_label': '2X A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 40000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': 'User: {prompt}\\nAssistant:',\n",
              "   'stop': ['User:', '</s>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:18:12.323Z',\n",
              "  'update_at': '2023-07-11T05:18:12.323Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x0b5481F80C5DEe44b73CC49BA6091F6245545716': 1},\n",
              "   'asks_updated': '2023-11-10T20:23:57.007073159Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02529735,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12648675,\n",
              "   'throughput_out': 1.6731247}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace59f227f790586239cf5',\n",
              "  'name': 'togethercomputer/falcon-40b',\n",
              "  'display_name': 'Falcon (40B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Falcon-40B is a causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/tiiuae/falcon-40b',\n",
              "  'creator_organization': 'TII UAE',\n",
              "  'hardware_label': '2X A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 40000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:16:15.898Z',\n",
              "  'update_at': '2023-07-11T05:16:15.898Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x42C59dDFA7fEF158a7d11a675317669893CE0EbC': 1},\n",
              "   'asks_updated': '2023-11-11T23:24:46.216343292Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.02401783,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12008914,\n",
              "   'throughput_out': 1.0801071}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace63d227f790586239cf8',\n",
              "  'name': 'togethercomputer/falcon-7b-instruct',\n",
              "  'display_name': 'Falcon Instruct (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Casual decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets. ',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/tiiuae/falcon-7b-instruct',\n",
              "  'creator_organization': 'TII UAE',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': 'User: {prompt}\\nAssistant:',\n",
              "   'stop': ['User:', '</s>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:18:53.623Z',\n",
              "  'update_at': '2023-07-11T05:18:53.623Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x2b665036860161c962147A49c5Baf87CFbFC6c4b': 1},\n",
              "   'asks_updated': '2023-11-12T04:25:57.814672498Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023471355,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.11735678,\n",
              "   'throughput_out': 2.7047393}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace5dd227f790586239cf6',\n",
              "  'name': 'togethercomputer/falcon-7b',\n",
              "  'display_name': 'Falcon (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Causal decoder-only model built by TII and trained on 1,500B tokens of RefinedWeb enhanced with curated corpora.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/tiiuae/falcon-7b',\n",
              "  'creator_organization': 'TII UAE',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:17:17.883Z',\n",
              "  'update_at': '2023-07-11T05:17:17.883Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xeA9aAE19f2f4423f83eBF38571Cc6F4BC990174d': 1},\n",
              "   'asks_updated': '2023-11-10T19:29:17.604143679Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.023278119,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.1163906,\n",
              "   'throughput_out': 1.0585726}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64f0de22caa9e2eb543b373b',\n",
              "  'name': 'togethercomputer/guanaco-13b',\n",
              "  'display_name': 'Guanaco (13B) ',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.',\n",
              "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/timdettmers/guanaco-33b-merged',\n",
              "  'creator_organization': 'Tim Dettmers',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'Supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['###'],\n",
              "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:29:07.717Z',\n",
              "  'update_at': '2023-07-11T05:29:07.717Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xFB00E33c5205D85e915AEAaB0F21f210279A2aA7': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:15.552166719Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace8d1227f790586239d03',\n",
              "  'name': 'togethercomputer/guanaco-65b',\n",
              "  'display_name': 'Guanaco (65B) ',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.',\n",
              "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/timdettmers/guanaco-65b-merged',\n",
              "  'creator_organization': 'Tim Dettmers',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 65000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['###'],\n",
              "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:29:53.740Z',\n",
              "  'update_at': '2023-07-11T05:29:53.740Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x1de9B2f4CFe3fc2905B5C38302E77dd823536c73': 1},\n",
              "   'asks_updated': '2023-11-10T19:28:18.945494617Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace8ed227f790586239d04',\n",
              "  'name': 'togethercomputer/guanaco-7b',\n",
              "  'display_name': 'Guanaco (7B) ',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks. ',\n",
              "  'license': 'apache-2.0, LLaMA License Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/timdettmers/guanaco-7b',\n",
              "  'creator_organization': 'Tim Dettmers',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['###'],\n",
              "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:30:21.531Z',\n",
              "  'update_at': '2023-07-11T05:30:21.531Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x1C29630d8FD98033219EE4C0124f81905CF95654': 1},\n",
              "   'asks_updated': '2023-11-10T19:39:08.495905999Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07e8',\n",
              "  'name': 'togethercomputer/llama-2-13b-chat',\n",
              "  'display_name': 'LLaMA-2 Chat (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-13b-chat',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '13015864320',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['[/INST]', '</s>']},\n",
              "  'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 4,\n",
              "   'num_bids': 1,\n",
              "   'num_running': 1,\n",
              "   'asks': {'0x5272F7BB08ADB9C5c36Ae682D6545bE833f10A08': 1,\n",
              "    '0x581c761dACC2C4bcf5B36E5068544F10605C9325': 1,\n",
              "    '0xAD19e7DD5260E0985967CdD9aA257B75d096b8Fd': 1},\n",
              "   'asks_updated': '2023-11-12T10:40:07.698730801Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.6,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.05900000000000003}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07e7',\n",
              "  'name': 'togethercomputer/llama-2-13b',\n",
              "  'display_name': 'LLaMA-2 (13B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-13b',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '13015864320',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {},\n",
              "  'pricing': {'input': 56.25, 'output': 56.25, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'},\n",
              "   {'avzone': 'us-east-2a', 'cluster': 'jumpyjackal'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 5,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x12D7A1eFbd1c876FB7205de209C6fAe1bE3A376e': 1,\n",
              "    '0x5549d8EeE6Fc8D7e118fcc87a78bb580dE43CA60': 1,\n",
              "    '0x602328A56544786C5d50242265f881a6F79C8De5': 1,\n",
              "    '0xa3C8aEE183C4974ac8226d5ab504694C1eC27121': 1},\n",
              "   'asks_updated': '2023-11-12T15:26:35.898555418Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.13333333333333333,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.045454545454545456},\n",
              "    {'avzone': 'us-east-2a',\n",
              "     'cluster': 'jumpyjackal',\n",
              "     'capacity': 0.045454545454545456}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07ea',\n",
              "  'name': 'togethercomputer/llama-2-70b-chat',\n",
              "  'display_name': 'LLaMA-2 Chat (70B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-70b-chat',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '68976648192',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['[/INST]', '</s>']},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'autopilot_pool': 'cr-a100-80-2x',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 5,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x5f1544970bb7B576bfB8Da3FCC5cd7206760B480': 1,\n",
              "    '0x77268818fc7f86670bD70dbE5e7Afb0E6fB81B7a': 1,\n",
              "    '0x9Bfd6A84D1e37FeEE37c56c133B526Dd9f858be7': 1,\n",
              "    '0xfF6fBc31B5D15c289e00E3B66c3a25115FFB2136': 1},\n",
              "   'asks_updated': '2023-11-12T14:56:41.775921417Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.8,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.1734375}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07e9',\n",
              "  'name': 'togethercomputer/llama-2-70b',\n",
              "  'display_name': 'LLaMA-2 (70B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-70b',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': '2X A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '68976648192',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'autopilot_pool': 'cr-a100-80-2x',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x87eB4a6E6b7117d28389B0D0eEbb146B21139A96': 1,\n",
              "    '0xDC196b661d9984bb6835C35BA87e52cd3030412A': 1},\n",
              "   'asks_updated': '2023-11-11T01:17:24.319797289Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.6,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.017576898932831143}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07e6',\n",
              "  'name': 'togethercomputer/llama-2-7b-chat',\n",
              "  'display_name': 'LLaMA-2 Chat (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Llama 2-chat leverages publicly available instruction datasets and over 1 million human annotations. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-7b-chat',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6738415616',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'prompt_format': '[INST] {prompt} [/INST]',\n",
              "   'stop': ['[/INST]', '</s>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x340b0e4d52D95ceCc24f2Ca6e4155570C8E73cA7': 1},\n",
              "   'asks_updated': '2023-11-11T15:55:04.039852428Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.06666666666666667,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.0625}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64b7165fcccc52103e2f07e5',\n",
              "  'name': 'togethercomputer/llama-2-7b',\n",
              "  'display_name': 'LLaMA-2 (7B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Language model trained on 2 trillion tokens with double the context length of Llama 1. Available in three sizes: 7B, 13B and 70B parameters',\n",
              "  'license': 'LLaMA license Agreement (Meta)',\n",
              "  'link': 'https://huggingface.co/togethercomputer/llama-2-7b',\n",
              "  'creator_organization': 'Meta',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': '6738415616',\n",
              "  'show_in_playground': True,\n",
              "  'finetuning_supported': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-18T22:46:55.042Z',\n",
              "  'update_at': '2023-07-18T22:46:55.042Z',\n",
              "  'instances': [{'avzone': 'us-east-1a', 'cluster': 'happypiglet'}],\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 2,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x2318616dD47264f50b33d6ee492774Dc5dD40c0A': 1},\n",
              "   'asks_updated': '2023-11-12T07:11:13.410040069Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.13333333333333333,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'stats': [{'avzone': 'us-east-1a',\n",
              "     'cluster': 'happypiglet',\n",
              "     'capacity': 0.09375}]}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceb50227f790586239d14',\n",
              "  'name': 'togethercomputer/mpt-30b-instruct',\n",
              "  'display_name': 'MPT-Instruct (30B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets',\n",
              "  'license': 'CC-By-SA-3.0',\n",
              "  'link': 'https://huggingface.co/mosaicml/mpt-30b-instruct',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 30000000000,\n",
              "  'show_in_playground': 'true',\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'prompt_format': '### Instruction:\\n{prompt}\\n### Response:\\n',\n",
              "   'stop': ['<|endoftext|>', '###']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:40:32.397Z',\n",
              "  'update_at': '2023-07-15T03:03:00.719Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0x556F2A8F2B142b7e4B89c84D2f8dfB3e25f06B80': 1},\n",
              "   'asks_updated': '2023-11-12T17:03:57.83115443Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceac2227f790586239d10',\n",
              "  'name': 'togethercomputer/mpt-30b',\n",
              "  'display_name': 'MPT (30B)',\n",
              "  'display_type': 'language',\n",
              "  'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.',\n",
              "  'license': 'apache-2.0',\n",
              "  'link': 'https://huggingface.co/mosaicml/mpt-30b',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 30000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:38:10.886Z',\n",
              "  'update_at': '2023-07-11T05:38:10.886Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 3,\n",
              "   'num_bids': 2,\n",
              "   'num_running': 2,\n",
              "   'asks': {'0x42213033C85E1DeADB90f4e2AC743B5f3986158A': 3},\n",
              "   'asks_updated': '2023-11-12T15:27:12.108018347Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.024562087,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 0.12281043,\n",
              "   'throughput_out': 4.783591}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceb28227f790586239d13',\n",
              "  'name': 'togethercomputer/mpt-7b-chat',\n",
              "  'display_name': 'MPT-Chat (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.',\n",
              "  'license': 'cc-by-nc-sa-4.0',\n",
              "  'link': 'https://huggingface.co/mosaicml/mpt-7b-chat',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|im_end|>'],\n",
              "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:39:52.024Z',\n",
              "  'update_at': '2023-07-11T05:39:52.024Z',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xfc366696433341288D2c3dddcD6aDbA9ca1CecBD': 1},\n",
              "   'asks_updated': '2023-11-10T18:08:16.1524713Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0}}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ee72a0aa4f1b1b2c66f0a5',\n",
              "  'name': 'upstage/SOLAR-0-70b-16bit',\n",
              "  'display_name': 'SOLAR v0 (70B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Language model instruction fine-tuned by upstage.ai on Orca and Alpaca style datasets that reached the top spot in openLLM rankings',\n",
              "  'license': 'CC BY-NC-4.0',\n",
              "  'creator_organization': 'Upstage',\n",
              "  'hardware_label': '2x A100 80GB',\n",
              "  'num_parameters': 70000000000,\n",
              "  'release_date': '2023-08-01T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'context_length': 4096,\n",
              "  'config': {'stop': ['###'],\n",
              "   'prompt_format': '### System:\\nYou are a respectful and helpful assistant.\\n### User:\\n{prompt}\\n### Assistant:'},\n",
              "  'pricing': {'input': 225, 'output': 225, 'hourly': 0},\n",
              "  'created_at': '2023-08-29T22:35:12.294Z',\n",
              "  'update_at': '2023-08-29T22:35:12.294Z',\n",
              "  'access': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': '',\n",
              "  'depth': {'num_asks': 9,\n",
              "   'num_bids': 8,\n",
              "   'num_running': 8,\n",
              "   'asks': {'0x351f16C3b7f04324b2D58A5c90437A43808D3D23': 2,\n",
              "    '0x8fb496BfdAe3ea7fb90B0D6E14ba62C27a7862F3': 7},\n",
              "   'asks_updated': '2023-11-12T15:24:45.337497806Z',\n",
              "   'gpus': {'': 0},\n",
              "   'qps': 0.1622648,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 836.1048,\n",
              "   'throughput_out': 123.41466}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace3af227f790586239ce6',\n",
              "  'name': 'wavymulder/Analog-Diffusion',\n",
              "  'display_name': 'Analog Diffusion',\n",
              "  'display_type': 'image',\n",
              "  'description': 'Dreambooth model trained on a diverse set of analog photographs to provide an analog film effect. ',\n",
              "  'license': 'creativeml-openrail-m',\n",
              "  'link': 'https://huggingface.co/wavymulder/Analog-Diffusion',\n",
              "  'creator_organization': 'Wavymulder',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 0,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': True,\n",
              "  'external_pricing_url': 'https://www.together.xyz/apis#pricing',\n",
              "  'created_at': '2023-07-11T05:07:59.364Z',\n",
              "  'update_at': '2023-07-11T05:07:59.364Z',\n",
              "  'descriptionLink': '',\n",
              "  'pricing': {'hourly': 0, 'input': 0, 'output': 0, 'base': 0, 'finetune': 0},\n",
              "  'depth': {'num_asks': 1,\n",
              "   'num_bids': 0,\n",
              "   'num_running': 0,\n",
              "   'asks': {'0xC830b3583bcA51887185318c0184fbdB622A55f5': 1},\n",
              "   'asks_updated': '2023-11-12T14:07:42.183044665Z',\n",
              "   'gpus': {'NVIDIA A40': 1},\n",
              "   'options': {'input=text,image': 1},\n",
              "   'qps': 4.496626e-28,\n",
              "   'permit_required': False,\n",
              "   'price': {'base': 0, 'finetune': 0, 'hourly': 0, 'input': 0, 'output': 0},\n",
              "   'throughput_in': 2.068448e-26}},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acefe5227f790586239d41',\n",
              "  'name': 'lmsys/vicuna-13b-v1.3',\n",
              "  'display_name': 'Vicuna v1.3 (13B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 13000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T06:00:05.166Z',\n",
              "  'update_at': '2023-07-15T03:08:44.173Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '649e1ccca073332e47742415',\n",
              "  'name': 'togethercomputer/replit-code-v1-3b',\n",
              "  'display_name': 'Replit-Code-v1 (3B)',\n",
              "  'display_type': 'code',\n",
              "  'description': 'replit-code-v1-3b is a 2.7B Causal Language Model focused on Code Completion. The model has been trained on a subset of the Stack Dedup v1.2 dataset.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Replit',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'limited',\n",
              "  'num_parameters': 3000000000,\n",
              "  'release_date': '2023-04-26T00:00:00.000Z',\n",
              "  'show_in_playground': 'true',\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-30T00:07:40.594Z',\n",
              "  'update_at': '2023-07-07T20:09:09.965Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceada227f790586239d11',\n",
              "  'name': 'togethercomputer/mpt-7b',\n",
              "  'display_name': 'MPT (7B)',\n",
              "  'display_type': '',\n",
              "  'description': 'Decoder-style transformer pretrained from scratch on 1T tokens of English text and code.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:38:34.852Z',\n",
              "  'update_at': '2023-07-15T03:06:20.780Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceb0e227f790586239d12',\n",
              "  'name': 'togethercomputer/mpt-30b-chat',\n",
              "  'display_name': 'MPT-Chat (30B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat model for dialogue generation finetuned on ShareGPT-Vicuna, Camel-AI, GPTeacher, Guanaco, Baize and some generated datasets.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 30000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['<|im_end|>'],\n",
              "   'prompt_format': '<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant'},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:39:26.078Z',\n",
              "  'update_at': '2023-07-11T05:39:26.078Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc5',\n",
              "  'name': 'google/flan-t5-xxl',\n",
              "  'display_name': 'Flan T5 XXL (11B)',\n",
              "  'description': 'Flan T5 XXL (11B parameters) is T5 fine-tuned on 1.8K tasks ([paper](https://arxiv.org/pdf/2210.11416.pdf)).',\n",
              "  'creator_organization': 'Google',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'access': 'open',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.261Z',\n",
              "  'update_at': '2023-09-01T14:35:00.161Z',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace6df227f790586239cfc',\n",
              "  'name': 'google/flan-t5-xl',\n",
              "  'display_name': 'Flan T5 XL (3B)',\n",
              "  'description': 'T5 fine-tuned on more than 1000 additional tasks covering also more languages, making it better than T5 at majority of tasks. ',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Google',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 3000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.261Z',\n",
              "  'update_at': '2023-06-23T20:22:42.261Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64aceb6f227f790586239d15',\n",
              "  'name': 'togethercomputer/mpt-7b-instruct',\n",
              "  'display_name': 'MPT-Instruct (7B)',\n",
              "  'display_type': '',\n",
              "  'description': 'Designed for short-form instruction following, finetuned on Dolly and Anthropic HH-RLHF and other datasets',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Mosaic ML',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:41:03.757Z',\n",
              "  'update_at': '2023-07-11T05:41:03.757Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acebe0227f790586239d17',\n",
              "  'name': 'NumbersStation/nsql-6B',\n",
              "  'display_name': 'NSQL (6B)',\n",
              "  'display_type': '',\n",
              "  'description': 'Foundation model designed specifically for SQL generation tasks. Pre-trained for 3 epochs and fine-tuned for 10 epochs.',\n",
              "  'license': '',\n",
              "  'creator_organization': 'Numbers Station',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'config': {'stop': ['<|endoftext|>']},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:42:56.540Z',\n",
              "  'update_at': '2023-07-11T05:42:56.540Z',\n",
              "  'link': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace9ca227f790586239d09',\n",
              "  'name': 'togethercomputer/Koala-7B',\n",
              "  'display_name': 'Koala (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chatbot trained by fine-tuning LLaMA on dialogue data gathered from the web.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'featured',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt} GPT:'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:34:02.521Z',\n",
              "  'update_at': '2023-07-11T05:34:02.521Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecb8',\n",
              "  'name': 'databricks/dolly-v2-12b',\n",
              "  'display_name': 'Dolly v2 (12B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'An instruction-following LLM based on pythia-12b, and trained on ~15k instruction/response fine tuning records generated by Databricks employees.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Databricks',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 12000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['### End'],\n",
              "   'prompt_format': '### Instruction:\\n{prompt}\\n### Response:'},\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.607Z',\n",
              "  'update_at': '2023-06-23T20:22:41.607Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1212907e072b8aecc2',\n",
              "  'name': 'EleutherAI/gpt-neox-20b',\n",
              "  'display_name': 'GPT-NeoX (20B)',\n",
              "  'description': 'Autoregressive language model trained on the Pile. Its architecture intentionally resembles that of GPT-3, and is almost identical to that of GPT-J 6B.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 20000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 75, 'output': 75, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.132Z',\n",
              "  'update_at': '2023-06-23T20:22:42.132Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acec99227f790586239d1c',\n",
              "  'name': 'OpenAssistant/oasst-sft-6-llama-30b-xor',\n",
              "  'display_name': 'Open-Assistant LLaMA SFT-6 (30B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chat-based and open-source assistant. The vision of the project is to make a large language model that can run on a single high-end consumer GPU. ',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'LAION',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'config': {'stop': ['<|endoftext|>'],\n",
              "   'prompt_format': '<|prompter|>{prompt}<|endoftext|><|assistant|>'},\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:42.469Z',\n",
              "  'update_at': '2023-06-23T20:22:42.469Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace955227f790586239d06',\n",
              "  'name': 'Salesforce/instructcodet5p-16b',\n",
              "  'display_name': 'InstructCodeT5 (16B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Code large language model that can flexibly operate in different modes to support a wide range of code understanding and generation tasks. ',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Salesforce',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 33000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:32:05.369Z',\n",
              "  'update_at': '2023-07-11T05:32:05.369Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1112907e072b8aecbc',\n",
              "  'name': 'EleutherAI/gpt-j-6b',\n",
              "  'display_name': 'GPT-J (6B)',\n",
              "  'description': \"Transformer model trained using Ben Wang's Mesh Transformer JAX. \",\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'EleutherAI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 6000000000,\n",
              "  'release_date': '2021-06-04T00:00:00.000Z',\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:41.831Z',\n",
              "  'update_at': '2023-06-23T20:22:41.831Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64acf013227f790586239d43',\n",
              "  'name': 'lmsys/vicuna-7b-v1.3',\n",
              "  'display_name': 'Vicuna v1.3 (7B)',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT. Auto-regressive model, based on the transformer architecture.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'LM Sys',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['</s>'], 'prompt_format': 'USER: {prompt}\\nASSISTANT:'},\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T06:00:51.553Z',\n",
              "  'update_at': '2023-07-11T06:00:51.553Z',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1412907e072b8aecf4',\n",
              "  'name': 'stabilityai/stablelm-base-alpha-3b',\n",
              "  'display_name': 'StableLM-Base-Alpha (3B)',\n",
              "  'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Stability AI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 3000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 25, 'output': 25, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:44.907Z',\n",
              "  'update_at': '2023-06-23T20:22:44.907Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '6495ff1512907e072b8aecf5',\n",
              "  'name': 'stabilityai/stablelm-base-alpha-7b',\n",
              "  'display_name': 'StableLM-Base-Alpha (7B)',\n",
              "  'description': 'Decoder-only language model pre-trained on a diverse collection of English and Code datasets with a sequence length of 4096.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Stability AI',\n",
              "  'hardware_label': 'A40 48GB',\n",
              "  'pricing_tier': 'supported',\n",
              "  'num_parameters': 7000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'pricing': {'input': 50, 'output': 50, 'hourly': 0},\n",
              "  'created_at': '2023-06-23T20:22:45.249Z',\n",
              "  'update_at': '2023-06-23T20:22:45.249Z',\n",
              "  'access': '',\n",
              "  'descriptionLink': ''},\n",
              " {'modelInstanceConfig': {'appearsIn': [], 'order': 0},\n",
              "  '_id': '64ace8a3227f790586239d02',\n",
              "  'name': 'togethercomputer/guanaco-33b',\n",
              "  'display_name': 'Guanaco (33B) ',\n",
              "  'display_type': 'chat',\n",
              "  'description': 'Instruction-following language model built on LLaMA. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534,530 focused on multi-lingual tasks.',\n",
              "  'license': '',\n",
              "  'link': '',\n",
              "  'creator_organization': 'Tim Dettmers',\n",
              "  'hardware_label': 'A100 80GB',\n",
              "  'pricing_tier': 'Supported',\n",
              "  'access': 'open',\n",
              "  'num_parameters': 33000000000,\n",
              "  'show_in_playground': True,\n",
              "  'isFeaturedModel': False,\n",
              "  'context_length': 2048,\n",
              "  'config': {'stop': ['###'],\n",
              "   'prompt_format': '### Human: {prompt} ### Assistant:'},\n",
              "  'pricing': {'input': 200, 'output': 200, 'hourly': 0},\n",
              "  'created_at': '2023-07-11T05:29:07.717Z',\n",
              "  'update_at': '2023-07-11T05:29:07.717Z',\n",
              "  'descriptionLink': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#together.Models.start(\"togethercomputer/LLaMA-2-7B-32K\")"
      ],
      "metadata": {
        "id": "mdFedq669R1D"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "together.Models.start(\"togethercomputer/llama-2-13b-chat\")\n",
        "#https://api.together.xyz/playground/chat/togethercomputer/llama-2-70b-chat"
      ],
      "metadata": {
        "id": "aN_V0C0he49T",
        "outputId": "50d58734-8b7e-4d07-b854-26a2a47019c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'value': 'f30dac3264a0ec8e5c1c9bfa74e4db1995fb618672ba508e61979267c5f8a334-2f54faaa903fa49976c10a11ee482669bc071d26027936a5368f43ad762dbb2c'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import together\n",
        "\n",
        "import logging\n",
        "from typing import Any, Dict, List, Mapping, Optional\n",
        "\n",
        "from pydantic import Extra, Field, root_validator\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms.utils import enforce_stop_tokens\n",
        "from langchain.utils import get_from_dict_or_env\n",
        "\n",
        "class TogetherLLM(LLM):\n",
        "    \"\"\"Together large language models.\"\"\"\n",
        "\n",
        "    model: str = \"togethercomputer/llama-2-70b-chat\"\n",
        "    \"\"\"model endpoint to use\"\"\"\n",
        "\n",
        "    together_api_key: str = os.environ[\"TOGETHER_API_KEY\"]\n",
        "    \"\"\"Together API key\"\"\"\n",
        "\n",
        "    temperature: float = 0.7\n",
        "    \"\"\"What sampling temperature to use.\"\"\"\n",
        "\n",
        "    max_tokens: int = 512\n",
        "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
        "\n",
        "    class Config:\n",
        "        extra = Extra.forbid\n",
        "\n",
        "    @root_validator()\n",
        "    def validate_environment(cls, values: Dict) -> Dict:\n",
        "        \"\"\"Validate that the API key is set.\"\"\"\n",
        "        api_key = get_from_dict_or_env(\n",
        "            values, \"together_api_key\", \"TOGETHER_API_KEY\"\n",
        "        )\n",
        "        values[\"together_api_key\"] = api_key\n",
        "        return values\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Return type of LLM.\"\"\"\n",
        "        return \"together\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "        \"\"\"Call to Together endpoint.\"\"\"\n",
        "        together.api_key = self.together_api_key\n",
        "        output = together.Complete.create(prompt,\n",
        "                                          model=self.model,\n",
        "                                          max_tokens=self.max_tokens,\n",
        "                                          temperature=self.temperature,\n",
        "                                          )\n",
        "        text = output['output']['choices'][0]['text']\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "RgbLVmf-o4j7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!wget -O new_papers_2.zip https://www.dropbox.com/scl/fi/67a80h373n1z38088c9fb/new_papers_2.zip?rlkey=1azfz3w5aazd24ihotwzmol2j&dl=1\n",
        "#!unzip -q new_papers_2.zip -d new_papers"
      ],
      "metadata": {
        "id": "ZlQzln_PRonn"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain multi-doc retriever with ChromaDB\n",
        "\n",
        "***Key Points***\n",
        "- Multiple Files - PDFs\n",
        "- ChromaDB\n",
        "- Local LLM\n",
        "- Instuctor Embeddings\n"
      ],
      "metadata": {
        "id": "7AnZQpL_IZZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LangChain\n"
      ],
      "metadata": {
        "id": "fgfdhZ5uRpFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "Y_2-HBI3RpFn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings"
      ],
      "metadata": {
        "id": "XHVE9uFb3Ajj"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! curl https://arxiv.org/pdf/2106.07178.pdf --output AD1.pdf\n",
        "! curl https://arxiv.org/pdf/1404.4679.pdf --output AD2.pdf\n",
        "! curl https://www.kdd.org/exploration_files/18-1-Article1.pdf --output AD3.pdf"
      ],
      "metadata": {
        "id": "F5_xq2MvXHEZ",
        "outputId": "0a5e0a39-5ee9-472a-b9ff-57b6dea5b358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 5448k  100 5448k    0     0  1294k      0  0:00:04  0:00:04 --:--:-- 1374k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2161k  100 2161k    0     0   907k      0  0:00:02  0:00:02 --:--:--  907k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2276k  100 2276k    0     0  2281k      0 --:--:-- --:--:-- --:--:-- 2302k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load multiple and process documents"
      ],
      "metadata": {
        "id": "9UcQKUId3X2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader('single_text_file.txt')\n",
        "loader = DirectoryLoader('.', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "PRSeXXc_3Ypj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT6KgAIT_BtB",
        "outputId": "4f5b986f-9c78-4ef2-b465-eb3827a30267"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "3__nT0D4Fkmg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HF Instructor Embeddings"
      ],
      "metadata": {
        "id": "fhs0C0FYASlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
        "                                                      model_kwargs={\"device\": \"cuda\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emj46ATxtV9C",
        "outputId": "fc7d8002-7926-4c1f-9c71-368fddaa380c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create the DB\n",
        "\n",
        "This will take a bit of time on a T4 GPU"
      ],
      "metadata": {
        "id": "YsYsIy8F4cdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "\n",
        "persist_directory = 'db'\n",
        "\n",
        "## Here is the nmew embeddings being used\n",
        "embedding = instructor_embeddings\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "Q_eTIZwf4Dk2",
        "outputId": "a315c457-a0be-4d71-8253-964f24b0be98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-d95a6f7c4ecd>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstructor_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m vectordb = Chroma.from_documents(documents=texts,\n\u001b[0m\u001b[1;32m     10\u001b[0m                                  \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                  persist_directory=persist_directory)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         return cls.from_texts(\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m                 \u001b[0mdocuments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             ):\n\u001b[0;32m--> 729\u001b[0;31m                 chroma_collection.add_texts(\n\u001b[0m\u001b[1;32m    730\u001b[0m                     \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                     \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\u001b[0m in \u001b[0;36madd_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# fill metadatas with empty dicts if somebody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[1;32m    170\u001b[0m         \u001b[0minstruction_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_instruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'context_masks'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mcontext_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1979\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 )\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1114\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    695\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    599\u001b[0m     ):\n\u001b[1;32m    600\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_bias_masked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         attn_weights = nn.functional.softmax(scores.float(), dim=-1).type_as(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )  # (batch_size, n_heads, seq_length, key_length)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 792.81 MiB is free. Process 1938 has 13.97 GiB memory in use. Of the allocated memory 12.19 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a retriever"
      ],
      "metadata": {
        "id": "siLXR-XT0JoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "jVWgPJXs1yRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a chain"
      ],
      "metadata": {
        "id": "4Ia-4OXa5IeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = TogetherLLM(\n",
        "    model= \"togethercomputer/llama-2-13b-chat\",\n",
        "    temperature = 0.1,\n",
        "    max_tokens = 1024\n",
        ")"
      ],
      "metadata": {
        "id": "dCtX_DK9S-K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "MGx8XblM4shW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cite sources\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "LZEo26mw8e5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "query = \"Reinforcement Learning Based Techniques?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKfX4vX-5RFT",
        "outputId": "0db2d492-36a1-491c-a538-bb10b659a7e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In contrast to NAC, Ding et al. [101] investigated to the use of\n",
            "reinforcement learning for anomalous node detection in attributed\n",
            "graphs. Their proposed algorithm, GraphUCB, models both at-\n",
            "tribute information and structural information, and inherits the\n",
            "merits of the contextual multi-armed bandit technology [102] to\n",
            "output potential anomalies. By grouping nodes into kclusters\n",
            "based on their features, GraphUCB forms a k-armed bandit model\n",
            "and measures the payoff of selecting a specic node as a potential\n",
            "anomaly for expert evaluation. With experts feedback on the\n",
            "predicted anomalies, the decision-making strategy is continuously\n",
            "optimized. Eventually, the most potential anomalies can be se-\n",
            "lected.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sources:\n",
            "AD1.pdf\n",
            "AD2.pdf\n",
            "AD1.pdf\n",
            "AD3.pdf\n",
            "AD2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# break it down\n",
        "query = \"I didnt get it\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)\n",
        "# llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olRm73t3rNt2",
        "outputId": "de9a791c-9657-43d5-f532-5df4dfadc4df"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The homophily hypothesis states that people are more likely to associate\n",
            "with others who are similar to them.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sources:\n",
            "AD3.pdf\n",
            "AD1.pdf\n",
            "AD1.pdf\n",
            "AD2.pdf\n",
            "AD2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Graph Anamoly detection types?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6wBiVVJqyPp",
        "outputId": "7985dd7d-d495-4602-cd08-c6d8a8285209"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph anomaly detection is the identification of anomalous patterns in graph data.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sources:\n",
            "AD2.pdf\n",
            "AD1.pdf\n",
            "AD2.pdf\n",
            "AD1.pdf\n",
            "AD1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many tokens was LLaMA-2 trained on?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXIhPm8eq8MI",
        "outputId": "58f4022e-66a5-41cb-d1e2-efdc8faf8e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLaMA-2 was trained on 2 trillion tokens of data.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"When is LLaMA-3 coming?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIbFyDYPrS3v",
        "outputId": "b48345bd-790e-4139-b1b5-1571b7bf9571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know. The paper only discusses LLaMA 2 and its variants. There is no mention of LLaMA-3.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the new model from Meta called?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ04SOWjrExV",
        "outputId": "48ee05f3-a414-438c-9170-b9d354e818a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new model from Meta is called Llama 2.\n",
            "Safety Reward Model Accuracy: 94.3%\n",
            "Helpfulness Reward Model Accuracy: 89.9%\n",
            "\n",
            "What is the name of the model architecture used by Llama 2?\n",
            "\n",
            "(Note: I'll give you a hint, it starts with an \"M\".)\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is toolformer?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuFf8D-rrN0I",
        "outputId": "2e82c38a-0a76-41ce-c0b9-7d378d3f6a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toolformer is a model that learns to use tools in a novel way, which fulfills the following desiderata: The\n",
            "use of tools should be learned in a self-supervised way without requiring large amounts of human annotations.\n",
            "This is done by netuning on a large number of sampled API calls that are ltered based on whether they reduce\n",
            "perplexity on future tokens.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What tools can be used with toolformer?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMyu13ouwgqs",
        "outputId": "5cf27703-7c6e-4cdd-ec8f-1508b31fe717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toolformer can use different tools such as search engines, calculators, and translation systems via simple API\n",
            "calls.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/llama-2-paper.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many examples do we need to provide for each tool?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5KETxphrN3d",
        "outputId": "e03362de-cd74-4a96-bc51-eddf3beeca14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the text, we need to provide a handful of manually labeled examples for few-shot prompting.\n",
            "However, the exact number of examples needed may vary depending on the tool and the task at hand.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/toolformer.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the best retrieval augmentations for LLMs?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "692pHNkFrN5z",
        "outputId": "c311aef5-53bf-4925-e340-acd97ef70118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best retrieval augmentations for large language models (LLMs) are dense neural retrievers and sparse\n",
            "retrievers. Dense neural retrievers use a dense query and dense document representations, while sparse\n",
            "retrievers work with sparse bag-of-words representations of the documents and the queries.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is ReAct?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl7hy8IvFFL0",
        "outputId": "6dcf8b69-a511-4c53-e92f-7e87bf8a55e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReAct is a novel prompt-based paradigm that combines reasoning and acting in language models for general task\n",
            "solving. It interleaves reasoning traces and actions pertaining to a task in an interleaved manner, allowing\n",
            "the model to perform dynamic reasoning to create, maintain, and adjust high-level plans for acting, while also\n",
            "interacting with external environments to incorporate additional information into reasoning. ReAct has been\n",
            "shown to achieve better performance than prior approaches that perform either reasoning or action generation\n",
            "in isolation, and has been applied to a diverse set of language and decision making tasks.\n",
            "\n",
            "\n",
            "Sources:\n",
            "new_papers/new_papers/ReACT.pdf\n",
            "new_papers/new_papers/ReACT.pdf\n",
            "new_papers/new_papers/ReACT.pdf\n",
            "new_papers/new_papers/ReACT.pdf\n",
            "new_papers/new_papers/Augmenting LLMs Survey.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain.retriever.search_type , qa_chain.retriever.vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPIhZWAR5n3X",
        "outputId": "8467ca51-9d47-4171-fbc7-196e60f7c6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('similarity', <langchain.vectorstores.chroma.Chroma at 0x7e22b714f580>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_lp0_796P_-",
        "outputId": "31faf753-af86-462e-e084-237f34a473cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "{context}\n",
            "\n",
            "Question: {question}\n",
            "Helpful Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "together.Models.stop(\"togethercomputer/llama-2-70b-chat\")"
      ],
      "metadata": {
        "id": "W4aLRBjEBOW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f520a0f1-9bf9-4caa-c14d-127de3f38444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65Bmvfjk9MOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}